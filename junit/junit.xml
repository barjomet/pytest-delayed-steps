<?xml version="1.0" encoding="utf-8"?><testsuite errors="0" failures="0" name="pytest" skips="0" tests="75" time="2.016"><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_with_results_complex.py]" time="0.10491204261779785"><system-out>
Testing that running pytest on file test_steps_with_results_complex.py results in {&apos;passed&apos;: 16, &apos;failed&apos;: 0, &apos;skipped&apos;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests0, inifile:
plugins: metadata-1.7.0, html-1.19.0, harvest-1.0.1, faulthandler-1.5.0, cov-2.6.0
collected 16 items

test_run_all_tests.py ................                                   [100%]

========================== 16 passed in 0.06 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_generator_does_not_change_order.py]" time="0.06917452812194824"><system-out>
Testing that running pytest on file test_steps_generator_does_not_change_order.py results in {&apos;passed&apos;: 3, &apos;failed&apos;: 0, &apos;skipped&apos;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests1, inifile:
plugins: metadata-1.7.0, html-1.19.0, harvest-1.0.1, faulthandler-1.5.0, cov-2.6.0
collected 3 items

test_run_all_tests.py ...                                                [100%]

=============================== warnings summary ===============================
test_run_all_tests.py::test_synthesis
  /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest_harvest/results_session.py:341: UserWarning: [pytest-harvest] Test items status is not available. You should maybe install pytest-harvest with pip. If it is already the case, you case try to force-use it by adding `pytest_plugins = [&apos;harvest&apos;]` to your conftest.py. But for normal use this should not be required, installing with pip should be enough.
    warn(&quot;[pytest-harvest] Test items status is not available. You should maybe install pytest-harvest with &quot;

-- Docs: https://docs.pytest.org/en/latest/warnings.html
===================== 3 passed, 1 warnings in 0.02 seconds =====================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_wrapped_in_class.py]" time="0.062271833419799805"><system-out>
Testing that running pytest on file test_wrapped_in_class.py results in {&apos;passed&apos;: 1, &apos;failed&apos;: 0, &apos;skipped&apos;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests2, inifile:
plugins: metadata-1.7.0, html-1.19.0, harvest-1.0.1, faulthandler-1.5.0, cov-2.6.0
collected 1 item

test_run_all_tests.py .                                                  [100%]

=========================== 1 passed in 0.02 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_stackoverflow.py]" time="0.10221314430236816"><system-out>
Testing that running pytest on file test_stackoverflow.py results in {&apos;passed&apos;: 3, &apos;failed&apos;: 0, &apos;skipped&apos;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests3, inifile:
plugins: metadata-1.7.0, html-1.19.0, harvest-1.0.1, faulthandler-1.5.0, cov-2.6.0
collected 3 items

test_run_all_tests.py ...                                                [100%]

=========================== 3 passed in 0.02 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_new_with_generator.py]" time="0.20624470710754395"><system-out>
Testing that running pytest on file test_steps_new_with_generator.py results in {&apos;passed&apos;: 12, &apos;failed&apos;: 2, &apos;skipped&apos;: 2}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests4, inifile:
plugins: metadata-1.7.0, html-1.19.0, harvest-1.0.1, faulthandler-1.5.0, cov-2.6.0
collected 16 items

test_run_all_tests.py ....Fs.Fs.......                                   [100%]

=================================== FAILURES ===================================
________________ test_suite_exception_on_mandatory_step[step_b] ________________

________step_name_ = &apos;step_b&apos;
request = &lt;FixtureRequest for &lt;Function &apos;test_suite_exception_on_mandatory_step[step_b]&apos;&gt;&gt;

&gt;   ???

&lt;decorator-gen-17&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/travis/build/smarie/python-pytest-steps/pytest_steps/decorator_hack.py:167: in caller
    **kwargs)
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:432: in step_function_wrapper
    steps_monitor.execute(step_name, *args, **kwargs)
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:270: in execute
    res = next(self.gen)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @test_steps(&apos;step_a&apos;, &apos;step_b&apos;, &apos;step_c&apos;)
    def test_suite_exception_on_mandatory_step():
        &quot;&quot;&quot; &quot;&quot;&quot;
    
        # Step A
        print(&quot;step a&quot;)
        assert not False  # replace with your logic
        yield &apos;step_a&apos;
    
        # Step B
        print(&quot;step b&quot;)
&gt;       assert False  # replace with your logic
E       assert False

test_run_all_tests.py:43: AssertionError
----------------------------- Captured stdout call -----------------------------
step b
_______________ test_suite_optional_and_dependent_steps[step_b] ________________

________step_name_ = &apos;step_b&apos;
request = &lt;FixtureRequest for &lt;Function &apos;test_suite_optional_and_dependent_steps[step_b]&apos;&gt;&gt;

&gt;   ???

&lt;decorator-gen-18&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/travis/build/smarie/python-pytest-steps/pytest_steps/decorator_hack.py:167: in caller
    **kwargs)
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:432: in step_function_wrapper
    steps_monitor.execute(step_name, *args, **kwargs)
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:292: in execute
    raise six.reraise(res.exec_result.exc_type, res.exec_result.exc_val, res.exec_result.tb)
/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/six.py:693: in reraise
    raise value
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @test_steps(&apos;step_a&apos;, &apos;step_b&apos;, &apos;step_c&apos;, &apos;step_d&apos;)
    def test_suite_optional_and_dependent_steps():
        &quot;&quot;&quot; &quot;&quot;&quot;
    
        # Step A
        print(&quot;step a&quot;)
        assert not False
        yield &apos;step_a&apos;
    
        # Step B
        with optional_step(&apos;step_b&apos;) as step_b:
            print(&quot;step b&quot;)
&gt;           assert False
E           assert False

test_run_all_tests.py:64: AssertionError
----------------------------- Captured stdout call -----------------------------
step b
================ 2 failed, 12 passed, 2 skipped in 0.16 seconds ================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_pytest_capabilities.py]" time="0.10145783424377441"><system-out>
Testing that running pytest on file test_pytest_capabilities.py results in {&apos;passed&apos;: 16, &apos;failed&apos;: 0, &apos;skipped&apos;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests5, inifile:
plugins: metadata-1.7.0, html-1.19.0, harvest-1.0.1, faulthandler-1.5.0, cov-2.6.0
collected 16 items

test_run_all_tests.py ................                                   [100%]

========================== 16 passed in 0.05 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_with_results_basic.py]" time="0.07048273086547852"><system-out>
Testing that running pytest on file test_steps_with_results_basic.py results in {&apos;passed&apos;: 4, &apos;failed&apos;: 0, &apos;skipped&apos;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests6, inifile:
plugins: metadata-1.7.0, html-1.19.0, harvest-1.0.1, faulthandler-1.5.0, cov-2.6.0
collected 4 items

test_run_all_tests.py ....                                               [100%]

=========================== 4 passed in 0.02 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_no_results.py]" time="0.06942057609558105"><system-out>
Testing that running pytest on file test_steps_no_results.py results in {&apos;passed&apos;: 4, &apos;failed&apos;: 0, &apos;skipped&apos;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests7, inifile:
plugins: metadata-1.7.0, html-1.19.0, harvest-1.0.1, faulthandler-1.5.0, cov-2.6.0
collected 4 items

test_run_all_tests.py ....                                               [100%]

=========================== 4 passed in 0.02 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_dependencies.py]" time="0.08565926551818848"><system-out>
Testing that running pytest on file test_steps_dependencies.py results in {&apos;passed&apos;: 3, &apos;failed&apos;: 2, &apos;skipped&apos;: 1}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests8, inifile:
plugins: metadata-1.7.0, html-1.19.0, harvest-1.0.1, faulthandler-1.5.0, cov-2.6.0
collected 6 items

test_run_all_tests.py .Fs.F.                                             [100%]

=================================== FAILURES ===================================
________________________ test_suite_no_results[step_b] _________________________

test_step = &lt;function step_b at 0x7f31d4479488&gt;
request = &lt;FixtureRequest for &lt;Function &apos;test_suite_no_results[step_b]&apos;&gt;&gt;

    @test_steps(step_a, step_b, step_c)
    def test_suite_no_results(test_step, request):
        &quot;&quot;&quot; In this test suite, the last step will be skipped because the second step failed (and there is a dependency) &quot;&quot;&quot;
    
        # Execute the step
&gt;       test_step()

test_run_all_tests.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def step_b():
        &quot;&quot;&quot; Step a of the test &quot;&quot;&quot;
    
        # perform this step
        print(&quot;step b&quot;)
&gt;       assert False
E       assert False

test_run_all_tests.py:20: AssertionError
----------------------------- Captured stdout call -----------------------------
step b
_____________________________ test_suite_1[step_b] _____________________________

test_step = &apos;step_b&apos;

    @test_steps(&apos;step_a&apos;, &apos;step_b&apos;, &apos;step_c&apos;)
    def test_suite_1(test_step):
        &quot;&quot;&quot; In this test suite the last step can &quot;see&quot; the dependency so it is still executed ...&quot;&quot;&quot;
        # Execute the step according to name
        if test_step == &apos;step_a&apos;:
            step_a()
        elif test_step == &apos;step_b&apos;:
&gt;           step_b()

test_run_all_tests.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def step_b():
        &quot;&quot;&quot; Step a of the test &quot;&quot;&quot;
    
        # perform this step
        print(&quot;step b&quot;)
&gt;       assert False
E       assert False

test_run_all_tests.py:20: AssertionError
----------------------------- Captured stdout call -----------------------------
step b
================ 2 failed, 3 passed, 1 skipped in 0.04 seconds =================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_and_dependency_tree.py]" time="0.12231230735778809"><system-out>
Testing that running pytest on file test_steps_and_dependency_tree.py results in {&apos;passed&apos;: 8, &apos;failed&apos;: 1, &apos;skipped&apos;: 5}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests9, inifile:
plugins: metadata-1.7.0, html-1.19.0, harvest-1.0.1, faulthandler-1.5.0, cov-2.6.0
collected 14 items

test_run_all_tests.py ....Fs....ssss                                     [100%]

=================================== FAILURES ===================================
_____________________________ test_3_4[p=b-step3] ______________________________

________step_name_ = &apos;step3&apos;
request = &lt;FixtureRequest for &lt;Function &apos;test_3_4[p=b-step3]&apos;&gt;&gt;, p = &apos;b&apos;
results_dct = {&apos;step1&apos;: 1, &apos;step2&apos;: &apos;hello&apos;, &apos;step3&apos;: {&apos;a&apos;: &apos;bla&apos;, &apos;b&apos;: &apos;bla&apos;}, &apos;step4&apos;: {&apos;a&apos;: &apos;blabla&apos;}}

&gt;   ???

&lt;decorator-gen-24&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/travis/build/smarie/python-pytest-steps/pytest_steps/decorator_hack.py:167: in caller
    **kwargs)
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:432: in step_function_wrapper
    steps_monitor.execute(step_name, *args, **kwargs)
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:270: in execute
    res = next(self.gen)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

p = &apos;b&apos;
results_dct = {&apos;step1&apos;: 1, &apos;step2&apos;: &apos;hello&apos;, &apos;step3&apos;: {&apos;a&apos;: &apos;bla&apos;, &apos;b&apos;: &apos;bla&apos;}, &apos;step4&apos;: {&apos;a&apos;: &apos;blabla&apos;}}

    @test_steps(&apos;step3&apos;, &apos;step4&apos;)
    @pytest.mark.parametrize(&apos;p&apos;, [&apos;a&apos;, &apos;b&apos;], ids=&quot;p={}&quot;.format)
    def test_3_4(p, results_dct):
        if &apos;step2&apos; not in results_dct:
            pytest.skip(&quot;Can not start step 3: step 2 has not run successfuly&quot;)
        # step 3
        results_dct.setdefault(&apos;step3&apos;, dict())[p] = &apos;bla&apos;
        if p == &apos;b&apos;:
&gt;           assert False
E           assert False

test_run_all_tests.py:33: AssertionError
================ 1 failed, 8 passed, 5 skipped in 0.07 seconds =================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_stackoverflow2.py]" time="0.06427288055419922"><system-out>
Testing that running pytest on file test_stackoverflow2.py results in {&apos;passed&apos;: 3, &apos;failed&apos;: 0, &apos;skipped&apos;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests10, inifile:
plugins: metadata-1.7.0, html-1.19.0, harvest-1.0.1, faulthandler-1.5.0, cov-2.6.0
collected 3 items

test_run_all_tests.py ...                                                [100%]

=========================== 3 passed in 0.02 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_decorator" file="pytest_steps/tests/test_decorator.py" line="32" name="test_normal_normal" time="0.001722574234008789"><system-out>0
1
2
3
4
5
6
7
8
9
</system-out></testcase><testcase classname="pytest_steps.tests.test_decorator" file="pytest_steps/tests/test_decorator.py" line="42" name="test_normal_gen" time="0.0016887187957763672"><system-out>0
1
2
3
4
5
6
7
8
9
</system-out></testcase><testcase classname="pytest_steps.tests.test_decorator" file="pytest_steps/tests/test_decorator.py" line="55" name="test_gen_gen" time="0.0016751289367675781"><system-out>0
</system-out></testcase><testcase classname="pytest_steps.tests.test_decorator" file="pytest_steps/tests/test_decorator.py" line="66" name="test_gen_normal" time="0.0014781951904296875"><system-out>0
1
2
3
4
5
6
7
8
9
</system-out></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="50" name="test_my_app_bench[A-1-train]" time="0.002767324447631836"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="50" name="test_my_app_bench[A-1-score]" time="0.002056598663330078"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="50" name="test_my_app_bench[A-2-train]" time="0.0022695064544677734"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="50" name="test_my_app_bench[A-2-score]" time="0.002165079116821289"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="50" name="test_my_app_bench[B-1-train]" time="0.0021381378173828125"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="50" name="test_my_app_bench[B-1-score]" time="0.002188444137573242"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="50" name="test_my_app_bench[B-2-train]" time="0.0020799636840820312"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="50" name="test_my_app_bench[B-2-score]" time="0.002064943313598633"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="50" name="test_my_app_bench[C-1-train]" time="0.002462148666381836"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="50" name="test_my_app_bench[C-1-score]" time="0.0022237300872802734"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="50" name="test_my_app_bench[C-2-train]" time="0.0022377967834472656"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="50" name="test_my_app_bench[C-2-score]" time="0.0022988319396972656"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="71" name="test_synthesis" time="0.04150557518005371"><system-out>
Keys:
(&apos;test_my_app_bench[A-1]&apos;, &apos;train&apos;)
(&apos;test_my_app_bench[A-1]&apos;, &apos;score&apos;)
(&apos;test_my_app_bench[A-2]&apos;, &apos;train&apos;)
(&apos;test_my_app_bench[A-2]&apos;, &apos;score&apos;)
(&apos;test_my_app_bench[B-1]&apos;, &apos;train&apos;)
(&apos;test_my_app_bench[B-1]&apos;, &apos;score&apos;)
(&apos;test_my_app_bench[B-2]&apos;, &apos;train&apos;)
(&apos;test_my_app_bench[B-2]&apos;, &apos;score&apos;)
(&apos;test_my_app_bench[C-1]&apos;, &apos;train&apos;)
(&apos;test_my_app_bench[C-1]&apos;, &apos;score&apos;)
(&apos;test_my_app_bench[C-2]&apos;, &apos;train&apos;)
(&apos;test_my_app_bench[C-2]&apos;, &apos;score&apos;)

First node:
&apos;pytest_obj&apos;: &lt;function test_my_app_bench at 0x7f31d475c9d8&gt;
&apos;status&apos;: &apos;passed&apos;
&apos;duration_ms&apos;: 0.5085468292236328
&apos;algo_param&apos;: 1
&apos;dataset&apos;: &apos;my dataset #A&apos;
&apos;accuracy&apos;: 0.7856711220526471
                                     status      duration_ms    algo_param  dataset           accuracy
-----------------------------------  --------  -------------  ------------  -------------  -----------
(&apos;test_my_app_bench[A-1]&apos;, &apos;train&apos;)  passed         0.508547             1  my dataset #A    0.785671
(&apos;test_my_app_bench[A-1]&apos;, &apos;score&apos;)  passed         0.423431             1  my dataset #A  nan
(&apos;test_my_app_bench[A-2]&apos;, &apos;train&apos;)  passed         0.503302             2  my dataset #A    0.0655985
(&apos;test_my_app_bench[A-2]&apos;, &apos;score&apos;)  passed         0.49448              2  my dataset #A  nan
(&apos;test_my_app_bench[B-1]&apos;, &apos;train&apos;)  passed         0.47493              1  my dataset #B    0.0911564
(&apos;test_my_app_bench[B-1]&apos;, &apos;score&apos;)  passed         0.466347             1  my dataset #B  nan
(&apos;test_my_app_bench[B-2]&apos;, &apos;train&apos;)  passed         0.441074             2  my dataset #B    0.38143
(&apos;test_my_app_bench[B-2]&apos;, &apos;score&apos;)  passed         0.44775              2  my dataset #B  nan
(&apos;test_my_app_bench[C-1]&apos;, &apos;train&apos;)  passed         0.708818             1  my dataset #C    0.607818
(&apos;test_my_app_bench[C-1]&apos;, &apos;score&apos;)  passed         0.469685             1  my dataset #C  nan
(&apos;test_my_app_bench[C-2]&apos;, &apos;train&apos;)  passed         0.510931             2  my dataset #C    0.954094
(&apos;test_my_app_bench[C-2]&apos;, &apos;score&apos;)  passed         0.510693             2  my dataset #C  nan
test_id                   algo_param  dataset        train/status      train/duration_ms    train/accuracy  score/status      score/duration_ms
----------------------  ------------  -------------  --------------  -------------------  ----------------  --------------  -------------------
test_my_app_bench[A-1]             1  my dataset #A  passed                     0.508547         0.785671   passed                     0.423431
test_my_app_bench[A-2]             2  my dataset #A  passed                     0.503302         0.0655985  passed                     0.49448
test_my_app_bench[B-1]             1  my dataset #B  passed                     0.47493          0.0911564  passed                     0.466347
test_my_app_bench[B-2]             2  my dataset #B  passed                     0.441074         0.38143    passed                     0.44775
test_my_app_bench[C-1]             1  my dataset #C  passed                     0.708818         0.607818   passed                     0.469685
test_my_app_bench[C-2]             2  my dataset #C  passed                     0.510931         0.954094   passed                     0.510693
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="26" name="test_step_id_gen_mode_approx_conflict_params[p=a-a]" time="0.002021312713623047"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="26" name="test_step_id_gen_mode_approx_conflict_params[p=a-b]" time="0.0013136863708496094"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="26" name="test_step_id_gen_mode_approx_conflict_params[p=b-a]" time="0.0016739368438720703"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="26" name="test_step_id_gen_mode_approx_conflict_params[p=b-b]" time="0.0016319751739501953"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="33" name="test_step_id_gen_mode_approx_conflict_fixture[hello-b-foo-a]" time="0.001667022705078125"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="33" name="test_step_id_gen_mode_approx_conflict_fixture[hello-b-foo-b]" time="0.0016155242919921875"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="39" name="test_step_id_gen_mode_approx_conflict_params_and_no_conflict_fixture[1-p=a-a]" time="0.0016589164733886719"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="39" name="test_step_id_gen_mode_approx_conflict_params_and_no_conflict_fixture[1-p=a-b]" time="0.0018024444580078125"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="39" name="test_step_id_gen_mode_approx_conflict_params_and_no_conflict_fixture[1-p=b-a]" time="0.0017783641815185547"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="39" name="test_step_id_gen_mode_approx_conflict_params_and_no_conflict_fixture[1-p=b-b]" time="0.0017452239990234375"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="50" name="test_step_id_gen_mode_exact_conflict_with_param[a-a]" time="0.0016469955444335938"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="50" name="test_step_id_gen_mode_exact_conflict_with_param[a-b]" time="0.0015861988067626953"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="50" name="test_step_id_gen_mode_exact_conflict_with_param[b-a]" time="0.0015521049499511719"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="50" name="test_step_id_gen_mode_exact_conflict_with_param[b-b]" time="0.0016396045684814453"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="59" name="test_step_id_gen_mode_exact_conflict_with_fixture[b-a]" time="0.0016398429870605469"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="59" name="test_step_id_gen_mode_exact_conflict_with_fixture[b-b]" time="0.0016224384307861328"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="67" name="test_step_id_gen_mode_exact_conflict_with_param_and_fixture[b-a-a]" time="0.0018873214721679688"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="67" name="test_step_id_gen_mode_exact_conflict_with_param_and_fixture[b-a-b]" time="0.0018434524536132812"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="67" name="test_step_id_gen_mode_exact_conflict_with_param_and_fixture[b-b-a]" time="0.0019109249114990234"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="67" name="test_step_id_gen_mode_exact_conflict_with_param_and_fixture[b-b-b]" time="0.001861572265625"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="79" name="test_step_id_parametrize_mode_approx_conflict[p=a-a]" time="0.0018117427825927734"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="79" name="test_step_id_parametrize_mode_approx_conflict[p=a-b]" time="0.0018455982208251953"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="79" name="test_step_id_parametrize_mode_approx_conflict[p=b-a]" time="0.0018284320831298828"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="79" name="test_step_id_parametrize_mode_approx_conflict[p=b-b]" time="0.0018396377563476562"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="88" name="test_step_id_conflicts_parametrized2[1-p=a-a]" time="0.0017349720001220703"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="88" name="test_step_id_conflicts_parametrized2[1-p=a-b]" time="0.0018754005432128906"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="88" name="test_step_id_conflicts_parametrized2[1-p=b-a]" time="0.0019080638885498047"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="88" name="test_step_id_conflicts_parametrized2[1-p=b-b]" time="0.0019066333770751953"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="97" name="test_step_id_conflicts_parametrized3[b-p=a-a]" time="0.001924276351928711"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="97" name="test_step_id_conflicts_parametrized3[b-p=a-b]" time="0.0018651485443115234"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="97" name="test_step_id_conflicts_parametrized3[b-p=b-a]" time="0.001676797866821289"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="97" name="test_step_id_conflicts_parametrized3[b-p=b-b]" time="0.0019457340240478516"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="64" name="test_my_app_bench[A-1-train]" time="0.0025243759155273438"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="64" name="test_my_app_bench[A-1-score]" time="0.0023670196533203125"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="64" name="test_my_app_bench[A-2-train]" time="0.0022652149200439453"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="64" name="test_my_app_bench[A-2-score]" time="0.0021555423736572266"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="64" name="test_my_app_bench[B-1-train]" time="0.002252340316772461"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="64" name="test_my_app_bench[B-1-score]" time="0.0022144317626953125"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="64" name="test_my_app_bench[B-2-train]" time="0.0022306442260742188"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="64" name="test_my_app_bench[B-2-score]" time="0.0022025108337402344"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="64" name="test_my_app_bench[C-1-train]" time="0.002227783203125"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="64" name="test_my_app_bench[C-1-score]" time="0.0021212100982666016"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="64" name="test_my_app_bench[C-2-train]" time="0.0020945072174072266"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="64" name="test_my_app_bench[C-2-score]" time="0.0022194385528564453"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="85" name="test_basic" time="0.0013260841369628906"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="90" name="test_synthesis" time="0.0921781063079834"><system-out>
Keys:
test_my_app_bench[A-1-train]
test_my_app_bench[A-1-score]
test_my_app_bench[A-2-train]
test_my_app_bench[A-2-score]
test_my_app_bench[B-1-train]
test_my_app_bench[B-1-score]
test_my_app_bench[B-2-train]
test_my_app_bench[B-2-score]
test_my_app_bench[C-1-train]
test_my_app_bench[C-1-score]
test_my_app_bench[C-2-train]
test_my_app_bench[C-2-score]
test_basic

First node:
&apos;pytest_obj&apos;: &lt;function test_my_app_bench at 0x7f31d473ebf8&gt;
&apos;status&apos;: &apos;passed&apos;
&apos;duration_ms&apos;: 0.5726814270019531
&apos;________step_name_&apos;: &apos;train&apos;
&apos;algo_param&apos;: 1
&apos;dataset&apos;: &apos;my dataset #A&apos;
&apos;accuracy&apos;: 0.3642002236045051

Pivoted table:
test_id                   algo_param  dataset        train/status      train/duration_ms    train/accuracy  score/status      score/duration_ms  -/status      -/duration_ms
----------------------  ------------  -------------  --------------  -------------------  ----------------  --------------  -------------------  ----------  ---------------
test_my_app_bench[A-1]             1  my dataset #A  passed                     0.572681         0.3642     passed                     0.512838  nan                nan
test_my_app_bench[A-2]             2  my dataset #A  passed                     0.516891         0.817449   passed                     0.463724  nan                nan
test_my_app_bench[B-1]             1  my dataset #B  passed                     0.422716         0.634802   passed                     0.491142  nan                nan
test_my_app_bench[B-2]             2  my dataset #B  passed                     0.524759         0.678498   passed                     0.501394  nan                nan
test_my_app_bench[C-1]             1  my dataset #C  passed                     0.505209         0.0975289  passed                     0.447273  nan                nan
test_my_app_bench[C-2]             2  my dataset #C  passed                     0.491381         0.536318   passed                     0.466347  nan                nan
test_basic                       nan  nan            nan                      nan              nan          nan                      nan         passed               0.3407

Pivoted table (2):
test_id                   algo_param  dataset        train/status      train/duration_ms    train/accuracy  score/status      score/duration_ms  -/status      -/duration_ms
----------------------  ------------  -------------  --------------  -------------------  ----------------  --------------  -------------------  ----------  ---------------
test_my_app_bench[A-1]             1  my dataset #A  passed                     0.572681         0.3642     passed                     0.512838  nan                nan
test_my_app_bench[A-2]             2  my dataset #A  passed                     0.516891         0.817449   passed                     0.463724  nan                nan
test_my_app_bench[B-1]             1  my dataset #B  passed                     0.422716         0.634802   passed                     0.491142  nan                nan
test_my_app_bench[B-2]             2  my dataset #B  passed                     0.524759         0.678498   passed                     0.501394  nan                nan
test_my_app_bench[C-1]             1  my dataset #C  passed                     0.505209         0.0975289  passed                     0.447273  nan                nan
test_my_app_bench[C-2]             2  my dataset #C  passed                     0.491381         0.536318   passed                     0.466347  nan                nan
test_basic                       nan  nan            nan                      nan              nan          nan                      nan         passed               0.3407
</system-out></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="185" name="test_synthesis_not_flat" time="0.004173994064331055"></testcase></testsuite>