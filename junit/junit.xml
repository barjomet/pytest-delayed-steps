<?xml version="1.0" encoding="utf-8"?><testsuite errors="0" failures="0" name="pytest" skips="0" tests="86" time="1.349"><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_parammode_stackoverflow.py]" time="0.037702083587646484"><system-out>
Testing that running pytest on file test_steps_parammode_stackoverflow.py results in {&apos;skipped&apos;: 0, &apos;passed&apos;: 3, &apos;failed&apos;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-2.9.2, py-1.8.1, pluggy-0.3.1
rootdir: /tmp/pytest-of-travis/pytest-0/testdir/test_run_all_tests0, inifile: 
plugins: steps-1.7.3.dev4+g71a16b7, logging-2015.11.4, html-1.9.0, harvest-1.7.4, cov-2.6.0, cases-1.12.1
collected 3 items

test_run_all_tests.py ...

=========================== 3 passed in 0.01 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_parammode_with_results_basic.py]" time="0.03724169731140137"><system-out>
Testing that running pytest on file test_steps_parammode_with_results_basic.py results in {&apos;skipped&apos;: 0, &apos;passed&apos;: 4, &apos;failed&apos;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-2.9.2, py-1.8.1, pluggy-0.3.1
rootdir: /tmp/pytest-of-travis/pytest-0/testdir/test_run_all_tests1, inifile: 
plugins: steps-1.7.3.dev4+g71a16b7, logging-2015.11.4, html-1.9.0, harvest-1.7.4, cov-2.6.0, cases-1.12.1
collected 4 items

test_run_all_tests.py ....

=========================== 4 passed in 0.01 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_genmode.py]" time="0.15420174598693848"><system-out>
Testing that running pytest on file test_steps_genmode.py results in {&apos;skipped&apos;: 2, &apos;passed&apos;: 15, &apos;failed&apos;: 2}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-2.9.2, py-1.8.1, pluggy-0.3.1
rootdir: /tmp/pytest-of-travis/pytest-0/testdir/test_run_all_tests2, inifile: 
plugins: steps-1.7.3.dev4+g71a16b7, logging-2015.11.4, html-1.9.0, harvest-1.7.4, cov-2.6.0, cases-1.12.1
collected 19 items

test_run_all_tests.py .....Fs.Fs.........

=================================== FAILURES ===================================
________________ test_suite_exception_on_mandatory_step[step_b] ________________

________step_name_ = &apos;step_b&apos;
request = &lt;FixtureRequest for &lt;Function &apos;test_suite_exception_on_mandatory_step[step_b]&apos;&gt;&gt;

&gt;   ???

&lt;makefun-gen-35&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:493: in wrapped_test_function
    steps_monitor.execute(step_name, args, kwargs)
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:299: in execute
    res = next(self.gen)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @test_steps(&apos;step_a&apos;, &apos;step_b&apos;, &apos;step_c&apos;)
    def test_suite_exception_on_mandatory_step():
        &quot;&quot;&quot; &quot;&quot;&quot;
    
        # Step A
        print(&quot;step a&quot;)
        assert not False  # replace with your logic
        yield &apos;step_a&apos;
    
        # Step B
        print(&quot;step b&quot;)
&gt;       pytest.fail(&quot;Failed intentionally - this is normal&quot;)  # replace with your logic
E       Failed: Failed intentionally - this is normal

test_run_all_tests.py:60: Failed
----------------------------- Captured stdout call -----------------------------
step b
_______________ test_suite_optional_and_dependent_steps[step_b] ________________

________step_name_ = &apos;step_b&apos;
request = &lt;FixtureRequest for &lt;Function &apos;test_suite_optional_and_dependent_steps[step_b]&apos;&gt;&gt;

&gt;   ???

&lt;makefun-gen-36&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:493: in wrapped_test_function
    steps_monitor.execute(step_name, args, kwargs)
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:321: in execute
    reraise(res.exec_result.exc_type, res.exec_result.exc_val, res.exec_result.tb)
/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/six.py:693: in reraise
    raise value
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @test_steps(&apos;step_a&apos;, &apos;step_b&apos;, &apos;step_c&apos;, &apos;step_d&apos;)
    def test_suite_optional_and_dependent_steps():
        &quot;&quot;&quot; &quot;&quot;&quot;
    
        # Step A
        print(&quot;step a&quot;)
        assert not False
        yield &apos;step_a&apos;
    
        # Step B
        with optional_step(&apos;step_b&apos;) as step_b:
            print(&quot;step b&quot;)
&gt;           pytest.fail(&quot;Failed intentionally - this is normal&quot;)
E           Failed: Failed intentionally - this is normal

test_run_all_tests.py:81: Failed
----------------------------- Captured stdout call -----------------------------
step b
================ 2 failed, 15 passed, 2 skipped in 0.13 seconds ================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_wrapped_in_class.py]" time="0.07030010223388672"><system-out>
Testing that running pytest on file test_wrapped_in_class.py results in {&apos;skipped&apos;: 0, &apos;passed&apos;: 6, &apos;failed&apos;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-2.9.2, py-1.8.1, pluggy-0.3.1
rootdir: /tmp/pytest-of-travis/pytest-0/testdir/test_run_all_tests3, inifile: 
plugins: steps-1.7.3.dev4+g71a16b7, logging-2015.11.4, html-1.9.0, harvest-1.7.4, cov-2.6.0, cases-1.12.1
collected 6 items

test_run_all_tests.py ......

=========================== 6 passed in 0.05 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_pytest_parametrization_capabilities.py]" time="0.05256223678588867"><system-out>
Testing that running pytest on file test_pytest_parametrization_capabilities.py results in {&apos;skipped&apos;: 0, &apos;passed&apos;: 16, &apos;failed&apos;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-2.9.2, py-1.8.1, pluggy-0.3.1
rootdir: /tmp/pytest-of-travis/pytest-0/testdir/test_run_all_tests4, inifile: 
plugins: steps-1.7.3.dev4+g71a16b7, logging-2015.11.4, html-1.9.0, harvest-1.7.4, cov-2.6.0, cases-1.12.1
collected 16 items

test_run_all_tests.py ................

========================== 16 passed in 0.03 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_genmode_does_not_change_order.py]" time="0.0377655029296875"><system-out>
Testing that running pytest on file test_steps_genmode_does_not_change_order.py results in {&apos;skipped&apos;: 0, &apos;passed&apos;: 5, &apos;failed&apos;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-2.9.2, py-1.8.1, pluggy-0.3.1
rootdir: /tmp/pytest-of-travis/pytest-0/testdir/test_run_all_tests5, inifile: 
plugins: steps-1.7.3.dev4+g71a16b7, logging-2015.11.4, html-1.9.0, harvest-1.7.4, cov-2.6.0, cases-1.12.1
collected 5 items

test_run_all_tests.py .....

=========================== 5 passed in 0.01 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_parammode_no_results.py]" time="0.033823251724243164"><system-out>
Testing that running pytest on file test_steps_parammode_no_results.py results in {&apos;skipped&apos;: 0, &apos;passed&apos;: 4, &apos;failed&apos;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-2.9.2, py-1.8.1, pluggy-0.3.1
rootdir: /tmp/pytest-of-travis/pytest-0/testdir/test_run_all_tests6, inifile: 
plugins: steps-1.7.3.dev4+g71a16b7, logging-2015.11.4, html-1.9.0, harvest-1.7.4, cov-2.6.0, cases-1.12.1
collected 4 items

test_run_all_tests.py ....

=========================== 4 passed in 0.01 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_genmode_dependency_tree.py]" time="0.07146191596984863"><system-out>
Testing that running pytest on file test_steps_genmode_dependency_tree.py results in {&apos;skipped&apos;: 5, &apos;passed&apos;: 8, &apos;failed&apos;: 1}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-2.9.2, py-1.8.1, pluggy-0.3.1
rootdir: /tmp/pytest-of-travis/pytest-0/testdir/test_run_all_tests7, inifile: 
plugins: steps-1.7.3.dev4+g71a16b7, logging-2015.11.4, html-1.9.0, harvest-1.7.4, cov-2.6.0, cases-1.12.1
collected 14 items

test_run_all_tests.py ....Fs....ssss

=================================== FAILURES ===================================
_____________________________ test_3_4[p=b-step3] ______________________________

p = &apos;b&apos;
results_dct = {&apos;step1&apos;: 1, &apos;step2&apos;: &apos;hello&apos;, &apos;step3&apos;: {&apos;a&apos;: &apos;bla&apos;, &apos;b&apos;: &apos;bla&apos;}, &apos;step4&apos;: {&apos;a&apos;: &apos;blabla&apos;}}
________step_name_ = &apos;step3&apos;
request = &lt;FixtureRequest for &lt;Function &apos;test_3_4[p=b-step3]&apos;&gt;&gt;

&gt;   ???

&lt;makefun-gen-51&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:493: in wrapped_test_function
    steps_monitor.execute(step_name, args, kwargs)
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:299: in execute
    res = next(self.gen)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

p = &apos;b&apos;
results_dct = {&apos;step1&apos;: 1, &apos;step2&apos;: &apos;hello&apos;, &apos;step3&apos;: {&apos;a&apos;: &apos;bla&apos;, &apos;b&apos;: &apos;bla&apos;}, &apos;step4&apos;: {&apos;a&apos;: &apos;blabla&apos;}}

    @test_steps(&apos;step3&apos;, &apos;step4&apos;)
    @pytest.mark.parametrize(&apos;p&apos;, [&apos;a&apos;, &apos;b&apos;], ids=&quot;p={}&quot;.format)
    def test_3_4(p, results_dct):
        if &apos;step2&apos; not in results_dct:
            pytest.skip(&quot;Can not start step 3: step 2 has not run successfuly&quot;)
        # step 3
        results_dct.setdefault(&apos;step3&apos;, dict())[p] = &apos;bla&apos;
        if p == &apos;b&apos;:
&gt;           pytest.fail(&quot;Failed intentionally - this is normal&quot;)
E           Failed: Failed intentionally - this is normal

test_run_all_tests.py:33: Failed
================ 1 failed, 8 passed, 5 skipped in 0.05 seconds =================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_parammode_dependencies.py]" time="0.06535625457763672"><system-out>
Testing that running pytest on file test_steps_parammode_dependencies.py results in {&apos;skipped&apos;: 1, &apos;passed&apos;: 4, &apos;failed&apos;: 2}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-2.9.2, py-1.8.1, pluggy-0.3.1
rootdir: /tmp/pytest-of-travis/pytest-0/testdir/test_run_all_tests8, inifile: 
plugins: steps-1.7.3.dev4+g71a16b7, logging-2015.11.4, html-1.9.0, harvest-1.7.4, cov-2.6.0, cases-1.12.1
collected 7 items

test_run_all_tests.py .Fs..F.

=================================== FAILURES ===================================
________________________ test_suite_no_results[step_b] _________________________

request = &lt;FixtureRequest for &lt;Function &apos;test_suite_no_results[step_b]&apos;&gt;&gt;
test_step = &lt;function step_b at 0x7f16e4ac6c80&gt;

&gt;   ???

&lt;makefun-gen-53&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_parametrizer.py:173: in wrapped_test_function
    res = test_func(*args, **kwargs)
test_run_all_tests.py:54: in test_suite_no_results
    test_step()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def step_b():
        &quot;&quot;&quot; Step a of the test &quot;&quot;&quot;
    
        # perform this step
        print(&quot;step b&quot;)
&gt;       pytest.fail(&quot;Failed intentionally - this is normal&quot;)
E       Failed: Failed intentionally - this is normal

test_run_all_tests.py:37: Failed
----------------------------- Captured stdout call -----------------------------
step b
_____________________________ test_suite_1[step_b] _____________________________

test_step = &apos;step_b&apos;
request = &lt;FixtureRequest for &lt;Function &apos;test_suite_1[step_b]&apos;&gt;&gt;

&gt;   ???

&lt;makefun-gen-54&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_parametrizer.py:130: in wrapped_test_function
    return test_func(*args, **kwargs)
test_run_all_tests.py:83: in test_suite_1
    step_b()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def step_b():
        &quot;&quot;&quot; Step a of the test &quot;&quot;&quot;
    
        # perform this step
        print(&quot;step b&quot;)
&gt;       pytest.fail(&quot;Failed intentionally - this is normal&quot;)
E       Failed: Failed intentionally - this is normal

test_run_all_tests.py:37: Failed
----------------------------- Captured stdout call -----------------------------
step b
================ 2 failed, 4 passed, 1 skipped in 0.04 seconds =================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_parammode_stackoverflow2.py]" time="0.03305959701538086"><system-out>
Testing that running pytest on file test_steps_parammode_stackoverflow2.py results in {&apos;skipped&apos;: 0, &apos;passed&apos;: 3, &apos;failed&apos;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-2.9.2, py-1.8.1, pluggy-0.3.1
rootdir: /tmp/pytest-of-travis/pytest-0/testdir/test_run_all_tests9, inifile: 
plugins: steps-1.7.3.dev4+g71a16b7, logging-2015.11.4, html-1.9.0, harvest-1.7.4, cov-2.6.0, cases-1.12.1
collected 3 items

test_run_all_tests.py ...

=========================== 3 passed in 0.01 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_parammode_with_results_complex.py]" time="0.05264425277709961"><system-out>
Testing that running pytest on file test_steps_parammode_with_results_complex.py results in {&apos;skipped&apos;: 0, &apos;passed&apos;: 16, &apos;failed&apos;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-2.9.2, py-1.8.1, pluggy-0.3.1
rootdir: /tmp/pytest-of-travis/pytest-0/testdir/test_run_all_tests10, inifile: 
plugins: steps-1.7.3.dev4+g71a16b7, logging-2015.11.4, html-1.9.0, harvest-1.7.4, cov-2.6.0, cases-1.12.1
collected 16 items

test_run_all_tests.py ................

========================== 16 passed in 0.03 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_cross_steps_fixture" file="pytest_steps/tests/test_cross_steps_fixture.py" line="17" name="test_gen_mode[0-a]" time="0.0009610652923583984"><system-out>hello
</system-out></testcase><testcase classname="pytest_steps.tests.test_cross_steps_fixture" file="pytest_steps/tests/test_cross_steps_fixture.py" line="17" name="test_gen_mode[0-b]" time="0.0012297630310058594"><system-out>world
</system-out></testcase><testcase classname="pytest_steps.tests.test_cross_steps_fixture" file="pytest_steps/tests/test_cross_steps_fixture.py" line="34" name="test_params_mode[step_a-0]" time="0.0007932186126708984"><system-out>hello
</system-out></testcase><testcase classname="pytest_steps.tests.test_cross_steps_fixture" file="pytest_steps/tests/test_cross_steps_fixture.py" line="34" name="test_params_mode[step_b-0]" time="0.0007975101470947266"><system-out>world
</system-out></testcase><testcase classname="pytest_steps.tests.test_cross_steps_fixture" file="pytest_steps/tests/test_cross_steps_fixture.py" line="40" name="test_fixture_has_been_called_once_per_fun" time="0.0006864070892333984"></testcase><testcase classname="pytest_steps.tests.test_docs_example_manual_call" file="pytest_steps/tests/test_docs_example_manual_call.py" line="5" name="test_dummy_gen[first]" time="0.0008065700531005859"><system-out>hello
</system-out></testcase><testcase classname="pytest_steps.tests.test_docs_example_manual_call" file="pytest_steps/tests/test_docs_example_manual_call.py" line="5" name="test_dummy_gen[second]" time="0.0007395744323730469"><system-out>world
</system-out></testcase><testcase classname="pytest_steps.tests.test_docs_example_manual_call" file="pytest_steps/tests/test_docs_example_manual_call.py" line="22" name="test_dummy_param_deps[first]" time="0.0007517337799072266"><system-out>hello
</system-out></testcase><testcase classname="pytest_steps.tests.test_docs_example_manual_call" file="pytest_steps/tests/test_docs_example_manual_call.py" line="22" name="test_dummy_param_deps[second]" time="0.0007479190826416016"><system-out>world
</system-out></testcase><testcase classname="pytest_steps.tests.test_docs_example_manual_call" file="pytest_steps/tests/test_docs_example_manual_call.py" line="27" name="test_dummy_param[first]" time="0.0006759166717529297"><system-out>hello
</system-out></testcase><testcase classname="pytest_steps.tests.test_docs_example_manual_call" file="pytest_steps/tests/test_docs_example_manual_call.py" line="27" name="test_dummy_param[second]" time="0.0006554126739501953"><system-out>world
</system-out></testcase><testcase classname="pytest_steps.tests.test_docs_example_manual_call" file="pytest_steps/tests/test_docs_example_manual_call.py" line="35" name="test_manual_call[test_dummy_gen]" time="0.004892587661743164"><system-out>Help on function test_dummy_gen in module pytest_steps.tests.test_docs_example_manual_call:

test_dummy_gen(________step_name_, request)

None
hello
world
hello
hello
world
</system-out></testcase><testcase classname="pytest_steps.tests.test_docs_example_manual_call" file="pytest_steps/tests/test_docs_example_manual_call.py" line="35" name="test_manual_call[test_dummy_param_deps]" time="0.001813650131225586"><system-out>Help on function test_dummy_param_deps in module pytest_steps.tests.test_docs_example_manual_call:

test_dummy_param_deps(test_step, request)
    Executes the current step only if its dependencies are correct, and registers its execution result

None
hello
world
hello
hello
world
world
</system-out></testcase><testcase classname="pytest_steps.tests.test_docs_example_manual_call" file="pytest_steps/tests/test_docs_example_manual_call.py" line="35" name="test_manual_call[test_dummy_param]" time="0.0012922286987304688"><system-out>Help on function test_dummy_param in module pytest_steps.tests.test_docs_example_manual_call:

test_dummy_param(test_step, request)

None
hello
world
hello
hello
world
world
</system-out></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[1-A-train]" time="0.001230478286743164"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[1-A-score]" time="0.0011203289031982422"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[1-B-train]" time="0.0013778209686279297"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[1-B-score]" time="0.0011529922485351562"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[1-C-train]" time="0.0010554790496826172"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[1-C-score]" time="0.0010416507720947266"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[2-A-train]" time="0.0014529228210449219"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[2-A-score]" time="0.0011363029479980469"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[2-B-train]" time="0.0011265277862548828"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[2-B-score]" time="0.001026153564453125"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[2-C-train]" time="0.001119852066040039"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[2-C-score]" time="0.0011601448059082031"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="53" name="test_synthesis_df" time="0.08630967140197754"><system-out>
   `module_results_df` dataframe:

                                status    ...     accuracy
test_id                step_id            ...             
test_my_app_bench[1-A] train    passed    ...     0.674824
                       score    passed    ...          NaN
test_my_app_bench[1-B] train    passed    ...     0.453541
                       score    passed    ...          NaN
test_my_app_bench[1-C] train    passed    ...     0.550395
                       score    passed    ...          NaN
test_my_app_bench[2-A] train    passed    ...     0.231475
                       score    passed    ...          NaN
test_my_app_bench[2-B] train    passed    ...     0.081547
                       score    passed    ...          NaN
test_my_app_bench[2-C] train    passed    ...     0.449939
                       score    passed    ...          NaN

[12 rows x 6 columns]
                                     status      duration_ms    algo_param  dataset_param    dataset           accuracy
-----------------------------------  --------  -------------  ------------  ---------------  -------------  -----------
(&apos;test_my_app_bench[1-A]&apos;, &apos;train&apos;)  passed         0.261545             1  A                my dataset #A    0.674824
(&apos;test_my_app_bench[1-A]&apos;, &apos;score&apos;)  passed         0.243187             1  A                my dataset #A  nan
(&apos;test_my_app_bench[1-B]&apos;, &apos;train&apos;)  passed         0.221968             1  B                my dataset #B    0.453541
(&apos;test_my_app_bench[1-B]&apos;, &apos;score&apos;)  passed         0.196695             1  B                my dataset #B  nan
(&apos;test_my_app_bench[1-C]&apos;, &apos;train&apos;)  passed         0.216961             1  C                my dataset #C    0.550395
(&apos;test_my_app_bench[1-C]&apos;, &apos;score&apos;)  passed         0.204325             1  C                my dataset #C  nan
(&apos;test_my_app_bench[2-A]&apos;, &apos;train&apos;)  passed         0.599623             2  A                my dataset #A    0.231475
(&apos;test_my_app_bench[2-A]&apos;, &apos;score&apos;)  passed         0.280619             2  A                my dataset #A  nan
(&apos;test_my_app_bench[2-B]&apos;, &apos;train&apos;)  passed         0.200987             2  B                my dataset #B    0.0815466
(&apos;test_my_app_bench[2-B]&apos;, &apos;score&apos;)  passed         0.19145              2  B                my dataset #B  nan
(&apos;test_my_app_bench[2-C]&apos;, &apos;train&apos;)  passed         0.202179             2  C                my dataset #C    0.449939
(&apos;test_my_app_bench[2-C]&apos;, &apos;score&apos;)  passed         0.203848             2  C                my dataset #C  nan

   `module_results_df_steps_pivoted` dataframe:

                        algo_param      ...        score/dataset
test_id                                 ...                     
test_my_app_bench[1-A]           1      ...        my dataset #A
test_my_app_bench[1-B]           1      ...        my dataset #B
test_my_app_bench[1-C]           1      ...        my dataset #C
test_my_app_bench[2-A]           2      ...        my dataset #A
test_my_app_bench[2-B]           2      ...        my dataset #B
test_my_app_bench[2-C]           2      ...        my dataset #C

[6 rows x 9 columns]
test_id                   algo_param  dataset_param    train/status      train/duration_ms  train/dataset      train/accuracy  score/status      score/duration_ms  score/dataset
----------------------  ------------  ---------------  --------------  -------------------  ---------------  ----------------  --------------  -------------------  ---------------
test_my_app_bench[1-A]             1  A                passed                     0.261545  my dataset #A           0.674824   passed                     0.243187  my dataset #A
test_my_app_bench[1-B]             1  B                passed                     0.221968  my dataset #B           0.453541   passed                     0.196695  my dataset #B
test_my_app_bench[1-C]             1  C                passed                     0.216961  my dataset #C           0.550395   passed                     0.204325  my dataset #C
test_my_app_bench[2-A]             2  A                passed                     0.599623  my dataset #A           0.231475   passed                     0.280619  my dataset #A
test_my_app_bench[2-B]             2  B                passed                     0.200987  my dataset #B           0.0815466  passed                     0.19145   my dataset #B
test_my_app_bench[2-C]             2  C                passed                     0.202179  my dataset #C           0.449939   passed                     0.203848  my dataset #C
</system-out><system-err>/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pandas/core/reshape/merge.py:544: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)
  warnings.warn(msg, UserWarning)
</system-err></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="26" name="test_step_id_gen_mode_approx_conflict_params[p=a-a]" time="0.0009496212005615234"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="26" name="test_step_id_gen_mode_approx_conflict_params[p=a-b]" time="0.001024484634399414"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="26" name="test_step_id_gen_mode_approx_conflict_params[p=b-a]" time="0.0009644031524658203"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="26" name="test_step_id_gen_mode_approx_conflict_params[p=b-b]" time="0.001132965087890625"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="33" name="test_step_id_gen_mode_approx_conflict_fixture[hello-b-foo-a]" time="0.0007169246673583984"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="33" name="test_step_id_gen_mode_approx_conflict_fixture[hello-b-foo-b]" time="0.0007493495941162109"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="39" name="test_step_id_gen_mode_approx_conflict_params_and_no_conflict_fixture[p=a-1-a]" time="0.00089263916015625"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="39" name="test_step_id_gen_mode_approx_conflict_params_and_no_conflict_fixture[p=a-1-b]" time="0.0008928775787353516"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="39" name="test_step_id_gen_mode_approx_conflict_params_and_no_conflict_fixture[p=b-1-a]" time="0.0021131038665771484"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="39" name="test_step_id_gen_mode_approx_conflict_params_and_no_conflict_fixture[p=b-1-b]" time="0.0008723735809326172"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="50" name="test_step_id_gen_mode_exact_conflict_with_param[a-a]" time="0.0008521080017089844"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="50" name="test_step_id_gen_mode_exact_conflict_with_param[a-b]" time="0.0008478164672851562"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="50" name="test_step_id_gen_mode_exact_conflict_with_param[b-a]" time="0.0013146400451660156"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="50" name="test_step_id_gen_mode_exact_conflict_with_param[b-b]" time="0.0008571147918701172"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="59" name="test_step_id_gen_mode_exact_conflict_with_fixture[b-a]" time="0.0008761882781982422"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="59" name="test_step_id_gen_mode_exact_conflict_with_fixture[b-b]" time="0.0008082389831542969"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="67" name="test_step_id_gen_mode_exact_conflict_with_param_and_fixture[a-b-a]" time="0.0009405612945556641"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="67" name="test_step_id_gen_mode_exact_conflict_with_param_and_fixture[a-b-b]" time="0.0012526512145996094"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="67" name="test_step_id_gen_mode_exact_conflict_with_param_and_fixture[b-b-a]" time="0.0008943080902099609"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="67" name="test_step_id_gen_mode_exact_conflict_with_param_and_fixture[b-b-b]" time="0.0008475780487060547"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="79" name="test_step_id_parametrize_mode_approx_conflict[a-p=a]" time="0.0008909702301025391"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="79" name="test_step_id_parametrize_mode_approx_conflict[a-p=b]" time="0.0011925697326660156"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="79" name="test_step_id_parametrize_mode_approx_conflict[b-p=a]" time="0.0008387565612792969"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="79" name="test_step_id_parametrize_mode_approx_conflict[b-p=b]" time="0.0008649826049804688"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="88" name="test_step_id_conflicts_parametrized2[a-p=a-1]" time="0.000926971435546875"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="88" name="test_step_id_conflicts_parametrized2[a-p=b-1]" time="0.0010805130004882812"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="88" name="test_step_id_conflicts_parametrized2[b-p=a-1]" time="0.0009303092956542969"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="88" name="test_step_id_conflicts_parametrized2[b-p=b-1]" time="0.0009646415710449219"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="97" name="test_step_id_conflicts_parametrized3[a-p=a-b]" time="0.0009362697601318359"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="97" name="test_step_id_conflicts_parametrized3[a-p=b-b]" time="0.0009529590606689453"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="97" name="test_step_id_conflicts_parametrized3[b-p=a-b]" time="0.0009183883666992188"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="97" name="test_step_id_conflicts_parametrized3[b-p=b-b]" time="0.0008909702301025391"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[1-A-train]" time="0.0012965202331542969"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[1-A-score]" time="0.001058340072631836"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[1-B-train]" time="0.001360177993774414"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[1-B-score]" time="0.0010390281677246094"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[1-C-train]" time="0.0010519027709960938"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[1-C-score]" time="0.0011391639709472656"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[2-A-train]" time="0.0010728836059570312"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[2-A-score]" time="0.0011188983917236328"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[2-B-train]" time="0.001131296157836914"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[2-B-score]" time="0.001050710678100586"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[2-C-train]" time="0.0010552406311035156"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[2-C-score]" time="0.0010390281677246094"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="53" name="test_basic" time="0.0005586147308349609"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="58" name="test_synthesis" time="0.049831390380859375"><system-out>test_id                   algo_param  dataset_param    train/status      train/duration_ms  train/dataset      train/accuracy  score/status      score/duration_ms  score/dataset    -/status      -/duration_ms
----------------------  ------------  ---------------  --------------  -------------------  ---------------  ----------------  --------------  -------------------  ---------------  ----------  ---------------
test_my_app_bench[1-A]             1  A                passed                     0.227928  my dataset #A            0.873159  passed                     0.20957   my dataset #A    nan               nan
test_my_app_bench[1-B]             1  B                passed                     0.20051   my dataset #B            0.537019  passed                     0.199556  my dataset #B    nan               nan
test_my_app_bench[1-C]             1  C                passed                     0.217915  my dataset #C            0.323695  passed                     0.188351  my dataset #C    nan               nan
test_my_app_bench[2-A]             2  A                passed                     0.221729  my dataset #A            0.418996  passed                     0.191689  my dataset #A    nan               nan
test_my_app_bench[2-B]             2  B                passed                     0.28801   my dataset #B            0.845066  passed                     0.190735  my dataset #B    nan               nan
test_my_app_bench[2-C]             2  C                passed                     0.201464  my dataset #C            0.503351  passed                     0.18239   my dataset #C    nan               nan
test_basic                       nan  nan              nan                      nan         nan                    nan         nan                      nan         nan              passed              0.13113
</system-out></testcase><testcase classname="pytest_steps.tests.test_with_cases" file="pytest_steps/tests/test_with_cases.py" line="8" name="test_basic_modeling[case_dummy-a]" time="0.0009980201721191406"></testcase><testcase classname="pytest_steps.tests.test_with_cases" file="pytest_steps/tests/test_with_cases.py" line="8" name="test_basic_modeling[case_dummy-b]" time="0.0012066364288330078"></testcase></testsuite>