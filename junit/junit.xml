<?xml version="1.0" encoding="utf-8"?><testsuite errors="0" failures="0" name="pytest" skips="0" tests="74" time="2.072"><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_wrapped_in_class.py]" time="0.06923484802246094"><system-out>
Testing that running pytest on file test_wrapped_in_class.py results in {&apos;skipped&apos;: 0, &apos;failed&apos;: 0, &apos;passed&apos;: 1}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests0, inifile:
plugins: steps-1.3.1.dev3+g76a472a, metadata-1.7.0, html-1.19.0, harvest-1.4.2, faulthandler-1.5.0, cov-2.6.0
collected 1 item

test_run_all_tests.py .                                                  [100%]

=========================== 1 passed in 0.02 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_parammode_with_results_complex.py]" time="0.10623884201049805"><system-out>
Testing that running pytest on file test_steps_parammode_with_results_complex.py results in {&apos;skipped&apos;: 0, &apos;failed&apos;: 0, &apos;passed&apos;: 16}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests1, inifile:
plugins: steps-1.3.1.dev3+g76a472a, metadata-1.7.0, html-1.19.0, harvest-1.4.2, faulthandler-1.5.0, cov-2.6.0
collected 16 items

test_run_all_tests.py ................                                   [100%]

========================== 16 passed in 0.06 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_parammode_dependencies.py]" time="0.159193754196167"><system-out>
Testing that running pytest on file test_steps_parammode_dependencies.py results in {&apos;skipped&apos;: 1, &apos;failed&apos;: 2, &apos;passed&apos;: 4}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests2, inifile:
plugins: steps-1.3.1.dev3+g76a472a, metadata-1.7.0, html-1.19.0, harvest-1.4.2, faulthandler-1.5.0, cov-2.6.0
collected 7 items

test_run_all_tests.py .Fs..F.                                            [100%]

=================================== FAILURES ===================================
________________________ test_suite_no_results[step_b] _________________________

test_step = &lt;function step_b at 0x7efda94fa2f0&gt;
request = &lt;FixtureRequest for &lt;Function &apos;test_suite_no_results[step_b]&apos;&gt;&gt;

    @test_steps(step_a, step_b, step_c)
    def test_suite_no_results(test_step, request):
        &quot;&quot;&quot; In this test suite, the last step will be skipped because the second step failed (and there is a dependency) &quot;&quot;&quot;
    
        # Execute the step
&gt;       test_step()

test_run_all_tests.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def step_b():
        &quot;&quot;&quot; Step a of the test &quot;&quot;&quot;
    
        # perform this step
        print(&quot;step b&quot;)
&gt;       assert False
E       assert False

test_run_all_tests.py:27: AssertionError
----------------------------- Captured stdout call -----------------------------
step b
_____________________________ test_suite_1[step_b] _____________________________

test_step = &apos;step_b&apos;

    @test_steps(&apos;step_a&apos;, &apos;step_b&apos;, &apos;step_c&apos;)
    def test_suite_1(test_step):
        &quot;&quot;&quot; In this test suite the last step can &quot;see&quot; the dependency so it is still executed ...&quot;&quot;&quot;
        # Execute the step according to name
        if test_step == &apos;step_a&apos;:
            step_a()
        elif test_step == &apos;step_b&apos;:
&gt;           step_b()

test_run_all_tests.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def step_b():
        &quot;&quot;&quot; Step a of the test &quot;&quot;&quot;
    
        # perform this step
        print(&quot;step b&quot;)
&gt;       assert False
E       assert False

test_run_all_tests.py:27: AssertionError
----------------------------- Captured stdout call -----------------------------
step b
================ 2 failed, 4 passed, 1 skipped in 0.11 seconds =================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_parammode_no_results.py]" time="0.06826019287109375"><system-out>
Testing that running pytest on file test_steps_parammode_no_results.py results in {&apos;skipped&apos;: 0, &apos;failed&apos;: 0, &apos;passed&apos;: 4}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests3, inifile:
plugins: steps-1.3.1.dev3+g76a472a, metadata-1.7.0, html-1.19.0, harvest-1.4.2, faulthandler-1.5.0, cov-2.6.0
collected 4 items

test_run_all_tests.py ....                                               [100%]

=========================== 4 passed in 0.02 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_genmode.py]" time="0.18752789497375488"><system-out>
Testing that running pytest on file test_steps_genmode.py results in {&apos;skipped&apos;: 2, &apos;failed&apos;: 2, &apos;passed&apos;: 13}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests4, inifile:
plugins: steps-1.3.1.dev3+g76a472a, metadata-1.7.0, html-1.19.0, harvest-1.4.2, faulthandler-1.5.0, cov-2.6.0
collected 17 items

test_run_all_tests.py .....Fs.Fs.......                                  [100%]

=================================== FAILURES ===================================
________________ test_suite_exception_on_mandatory_step[step_b] ________________

________step_name_ = &apos;step_b&apos;
request = &lt;FixtureRequest for &lt;Function &apos;test_suite_exception_on_mandatory_step[step_b]&apos;&gt;&gt;

&gt;   ???

&lt;decorator-gen-17&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/travis/build/smarie/python-pytest-steps/pytest_steps/decorator_hack.py:167: in caller
    **kwargs)
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:453: in step_function_wrapper
    steps_monitor.execute(step_name, *args, **kwargs)
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:270: in execute
    res = next(self.gen)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @test_steps(&apos;step_a&apos;, &apos;step_b&apos;, &apos;step_c&apos;)
    def test_suite_exception_on_mandatory_step():
        &quot;&quot;&quot; &quot;&quot;&quot;
    
        # Step A
        print(&quot;step a&quot;)
        assert not False  # replace with your logic
        yield &apos;step_a&apos;
    
        # Step B
        print(&quot;step b&quot;)
&gt;       assert False  # replace with your logic
E       assert False

test_run_all_tests.py:59: AssertionError
----------------------------- Captured stdout call -----------------------------
step b
_______________ test_suite_optional_and_dependent_steps[step_b] ________________

________step_name_ = &apos;step_b&apos;
request = &lt;FixtureRequest for &lt;Function &apos;test_suite_optional_and_dependent_steps[step_b]&apos;&gt;&gt;

&gt;   ???

&lt;decorator-gen-18&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/travis/build/smarie/python-pytest-steps/pytest_steps/decorator_hack.py:167: in caller
    **kwargs)
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:453: in step_function_wrapper
    steps_monitor.execute(step_name, *args, **kwargs)
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:292: in execute
    raise six.reraise(res.exec_result.exc_type, res.exec_result.exc_val, res.exec_result.tb)
/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/six.py:693: in reraise
    raise value
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @test_steps(&apos;step_a&apos;, &apos;step_b&apos;, &apos;step_c&apos;, &apos;step_d&apos;)
    def test_suite_optional_and_dependent_steps():
        &quot;&quot;&quot; &quot;&quot;&quot;
    
        # Step A
        print(&quot;step a&quot;)
        assert not False
        yield &apos;step_a&apos;
    
        # Step B
        with optional_step(&apos;step_b&apos;) as step_b:
            print(&quot;step b&quot;)
&gt;           assert False
E           assert False

test_run_all_tests.py:80: AssertionError
----------------------------- Captured stdout call -----------------------------
step b
================ 2 failed, 13 passed, 2 skipped in 0.14 seconds ================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_parammode_stackoverflow2.py]" time="0.06741046905517578"><system-out>
Testing that running pytest on file test_steps_parammode_stackoverflow2.py results in {&apos;skipped&apos;: 0, &apos;failed&apos;: 0, &apos;passed&apos;: 3}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests5, inifile:
plugins: steps-1.3.1.dev3+g76a472a, metadata-1.7.0, html-1.19.0, harvest-1.4.2, faulthandler-1.5.0, cov-2.6.0
collected 3 items

test_run_all_tests.py ...                                                [100%]

=========================== 3 passed in 0.02 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_parammode_with_results_basic.py]" time="0.07093167304992676"><system-out>
Testing that running pytest on file test_steps_parammode_with_results_basic.py results in {&apos;skipped&apos;: 0, &apos;failed&apos;: 0, &apos;passed&apos;: 4}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests6, inifile:
plugins: steps-1.3.1.dev3+g76a472a, metadata-1.7.0, html-1.19.0, harvest-1.4.2, faulthandler-1.5.0, cov-2.6.0
collected 4 items

test_run_all_tests.py ....                                               [100%]

=========================== 4 passed in 0.02 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_genmode_does_not_change_order.py]" time="0.06798148155212402"><system-out>
Testing that running pytest on file test_steps_genmode_does_not_change_order.py results in {&apos;skipped&apos;: 0, &apos;failed&apos;: 0, &apos;passed&apos;: 3}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests7, inifile:
plugins: steps-1.3.1.dev3+g76a472a, metadata-1.7.0, html-1.19.0, harvest-1.4.2, faulthandler-1.5.0, cov-2.6.0
collected 3 items

test_run_all_tests.py ...                                                [100%]

=========================== 3 passed in 0.02 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_parammode_stackoverflow.py]" time="0.06781148910522461"><system-out>
Testing that running pytest on file test_steps_parammode_stackoverflow.py results in {&apos;skipped&apos;: 0, &apos;failed&apos;: 0, &apos;passed&apos;: 3}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests8, inifile:
plugins: steps-1.3.1.dev3+g76a472a, metadata-1.7.0, html-1.19.0, harvest-1.4.2, faulthandler-1.5.0, cov-2.6.0
collected 3 items

test_run_all_tests.py ...                                                [100%]

=========================== 3 passed in 0.02 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_pytest_parametrization_capabilities.py]" time="0.1090998649597168"><system-out>
Testing that running pytest on file test_pytest_parametrization_capabilities.py results in {&apos;skipped&apos;: 0, &apos;failed&apos;: 0, &apos;passed&apos;: 16}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests9, inifile:
plugins: steps-1.3.1.dev3+g76a472a, metadata-1.7.0, html-1.19.0, harvest-1.4.2, faulthandler-1.5.0, cov-2.6.0
collected 16 items

test_run_all_tests.py ................                                   [100%]

========================== 16 passed in 0.06 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_genmode_dependency_tree.py]" time="0.1255817413330078"><system-out>
Testing that running pytest on file test_steps_genmode_dependency_tree.py results in {&apos;skipped&apos;: 5, &apos;failed&apos;: 1, &apos;passed&apos;: 8}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests10, inifile:
plugins: steps-1.3.1.dev3+g76a472a, metadata-1.7.0, html-1.19.0, harvest-1.4.2, faulthandler-1.5.0, cov-2.6.0
collected 14 items

test_run_all_tests.py ....Fs....ssss                                     [100%]

=================================== FAILURES ===================================
_____________________________ test_3_4[p=b-step3] ______________________________

________step_name_ = &apos;step3&apos;
request = &lt;FixtureRequest for &lt;Function &apos;test_3_4[p=b-step3]&apos;&gt;&gt;, p = &apos;b&apos;
results_dct = {&apos;step1&apos;: 1, &apos;step2&apos;: &apos;hello&apos;, &apos;step3&apos;: {&apos;a&apos;: &apos;bla&apos;, &apos;b&apos;: &apos;bla&apos;}, &apos;step4&apos;: {&apos;a&apos;: &apos;blabla&apos;}}

&gt;   ???

&lt;decorator-gen-25&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/travis/build/smarie/python-pytest-steps/pytest_steps/decorator_hack.py:167: in caller
    **kwargs)
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:453: in step_function_wrapper
    steps_monitor.execute(step_name, *args, **kwargs)
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:270: in execute
    res = next(self.gen)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

p = &apos;b&apos;
results_dct = {&apos;step1&apos;: 1, &apos;step2&apos;: &apos;hello&apos;, &apos;step3&apos;: {&apos;a&apos;: &apos;bla&apos;, &apos;b&apos;: &apos;bla&apos;}, &apos;step4&apos;: {&apos;a&apos;: &apos;blabla&apos;}}

    @test_steps(&apos;step3&apos;, &apos;step4&apos;)
    @pytest.mark.parametrize(&apos;p&apos;, [&apos;a&apos;, &apos;b&apos;], ids=&quot;p={}&quot;.format)
    def test_3_4(p, results_dct):
        if &apos;step2&apos; not in results_dct:
            pytest.skip(&quot;Can not start step 3: step 2 has not run successfuly&quot;)
        # step 3
        results_dct.setdefault(&apos;step3&apos;, dict())[p] = &apos;bla&apos;
        if p == &apos;b&apos;:
&gt;           assert False
E           assert False

test_run_all_tests.py:33: AssertionError
================ 1 failed, 8 passed, 5 skipped in 0.08 seconds =================
</system-out></testcase><testcase classname="pytest_steps.tests.test_decorator" file="pytest_steps/tests/test_decorator.py" line="28" name="test_normal_normal" time="0.0019464492797851562"><system-out>0
1
2
3
4
5
6
7
8
9
</system-out></testcase><testcase classname="pytest_steps.tests.test_decorator" file="pytest_steps/tests/test_decorator.py" line="38" name="test_normal_gen" time="0.0021545886993408203"><system-out>0
1
2
3
4
5
6
7
8
9
</system-out></testcase><testcase classname="pytest_steps.tests.test_decorator" file="pytest_steps/tests/test_decorator.py" line="51" name="test_gen_gen" time="0.0019485950469970703"><system-out>0
</system-out></testcase><testcase classname="pytest_steps.tests.test_decorator" file="pytest_steps/tests/test_decorator.py" line="62" name="test_gen_normal" time="0.0020265579223632812"><system-out>0
1
2
3
4
5
6
7
8
9
</system-out></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[A-1-train]" time="0.0026123523712158203"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[A-1-score]" time="0.0031108856201171875"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[A-2-train]" time="0.003074169158935547"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[A-2-score]" time="0.0027036666870117188"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[B-1-train]" time="0.0026640892028808594"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[B-1-score]" time="0.002156972885131836"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[B-2-train]" time="0.00241851806640625"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[B-2-score]" time="0.0024607181549072266"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[C-1-train]" time="0.002526998519897461"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[C-1-score]" time="0.002533435821533203"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[C-2-train]" time="0.0022382736206054688"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[C-2-score]" time="0.002733469009399414"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="53" name="test_synthesis_df" time="0.08537673950195312"><system-out>
   `module_results_df` dataframe:

                                status    ...     accuracy
test_id                step_id            ...             
test_my_app_bench[A-1] train    passed    ...          NaN
                       score    passed    ...     0.819862
test_my_app_bench[A-2] train    passed    ...          NaN
                       score    passed    ...     0.066022
test_my_app_bench[B-1] train    passed    ...          NaN
                       score    passed    ...     0.642793
test_my_app_bench[B-2] train    passed    ...          NaN
                       score    passed    ...     0.487317
test_my_app_bench[C-1] train    passed    ...          NaN
                       score    passed    ...     0.997536
test_my_app_bench[C-2] train    passed    ...          NaN
                       score    passed    ...     0.249495

[12 rows x 6 columns]
                                     status      duration_ms    algo_param  dataset_param    dataset           accuracy
-----------------------------------  --------  -------------  ------------  ---------------  -------------  -----------
(&apos;test_my_app_bench[A-1]&apos;, &apos;train&apos;)  passed         0.513077             1  A                my dataset #A  nan
(&apos;test_my_app_bench[A-1]&apos;, &apos;score&apos;)  passed         0.6814               1  A                my dataset #A    0.819862
(&apos;test_my_app_bench[A-2]&apos;, &apos;train&apos;)  passed         0.718594             2  A                my dataset #A  nan
(&apos;test_my_app_bench[A-2]&apos;, &apos;score&apos;)  passed         0.582218             2  A                my dataset #A    0.0660221
(&apos;test_my_app_bench[B-1]&apos;, &apos;train&apos;)  passed         0.788927             1  B                my dataset #B  nan
(&apos;test_my_app_bench[B-1]&apos;, &apos;score&apos;)  passed         0.453949             1  B                my dataset #B    0.642793
(&apos;test_my_app_bench[B-2]&apos;, &apos;train&apos;)  passed         0.531197             2  B                my dataset #B  nan
(&apos;test_my_app_bench[B-2]&apos;, &apos;score&apos;)  passed         0.524044             2  B                my dataset #B    0.487317
(&apos;test_my_app_bench[C-1]&apos;, &apos;train&apos;)  passed         0.55933              1  C                my dataset #C  nan
(&apos;test_my_app_bench[C-1]&apos;, &apos;score&apos;)  passed         0.560522             1  C                my dataset #C    0.997536
(&apos;test_my_app_bench[C-2]&apos;, &apos;train&apos;)  passed         0.486374             2  C                my dataset #C  nan
(&apos;test_my_app_bench[C-2]&apos;, &apos;score&apos;)  passed         0.522137             2  C                my dataset #C    0.249495

   `module_results_df_steps_pivoted` dataframe:

                        algo_param      ...       score/accuracy
test_id                                 ...                     
test_my_app_bench[A-1]           1      ...             0.819862
test_my_app_bench[A-2]           2      ...             0.066022
test_my_app_bench[B-1]           1      ...             0.642793
test_my_app_bench[B-2]           2      ...             0.487317
test_my_app_bench[C-1]           1      ...             0.997536
test_my_app_bench[C-2]           2      ...             0.249495

[6 rows x 8 columns]
test_id                   algo_param  dataset_param    dataset        train/status      train/duration_ms  score/status      score/duration_ms    score/accuracy
----------------------  ------------  ---------------  -------------  --------------  -------------------  --------------  -------------------  ----------------
test_my_app_bench[A-1]             1  A                my dataset #A  passed                     0.513077  passed                     0.6814           0.819862
test_my_app_bench[A-2]             2  A                my dataset #A  passed                     0.718594  passed                     0.582218         0.0660221
test_my_app_bench[B-1]             1  B                my dataset #B  passed                     0.788927  passed                     0.453949         0.642793
test_my_app_bench[B-2]             2  B                my dataset #B  passed                     0.531197  passed                     0.524044         0.487317
test_my_app_bench[C-1]             1  C                my dataset #C  passed                     0.55933   passed                     0.560522         0.997536
test_my_app_bench[C-2]             2  C                my dataset #C  passed                     0.486374  passed                     0.522137         0.249495
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="26" name="test_step_id_gen_mode_approx_conflict_params[p=a-a]" time="0.002038240432739258"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="26" name="test_step_id_gen_mode_approx_conflict_params[p=a-b]" time="0.0018401145935058594"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="26" name="test_step_id_gen_mode_approx_conflict_params[p=b-a]" time="0.0018525123596191406"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="26" name="test_step_id_gen_mode_approx_conflict_params[p=b-b]" time="0.0017452239990234375"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="33" name="test_step_id_gen_mode_approx_conflict_fixture[hello-b-foo-a]" time="0.0016138553619384766"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="33" name="test_step_id_gen_mode_approx_conflict_fixture[hello-b-foo-b]" time="0.0018358230590820312"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="39" name="test_step_id_gen_mode_approx_conflict_params_and_no_conflict_fixture[1-p=a-a]" time="0.002013683319091797"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="39" name="test_step_id_gen_mode_approx_conflict_params_and_no_conflict_fixture[1-p=a-b]" time="0.0020084381103515625"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="39" name="test_step_id_gen_mode_approx_conflict_params_and_no_conflict_fixture[1-p=b-a]" time="0.002286195755004883"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="39" name="test_step_id_gen_mode_approx_conflict_params_and_no_conflict_fixture[1-p=b-b]" time="0.0018415451049804688"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="50" name="test_step_id_gen_mode_exact_conflict_with_param[a-a]" time="0.0016851425170898438"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="50" name="test_step_id_gen_mode_exact_conflict_with_param[a-b]" time="0.0018889904022216797"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="50" name="test_step_id_gen_mode_exact_conflict_with_param[b-a]" time="0.0018482208251953125"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="50" name="test_step_id_gen_mode_exact_conflict_with_param[b-b]" time="0.0018489360809326172"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="59" name="test_step_id_gen_mode_exact_conflict_with_fixture[b-a]" time="0.0018169879913330078"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="59" name="test_step_id_gen_mode_exact_conflict_with_fixture[b-b]" time="0.0017039775848388672"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="67" name="test_step_id_gen_mode_exact_conflict_with_param_and_fixture[b-a-a]" time="0.001951456069946289"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="67" name="test_step_id_gen_mode_exact_conflict_with_param_and_fixture[b-a-b]" time="0.0019223690032958984"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="67" name="test_step_id_gen_mode_exact_conflict_with_param_and_fixture[b-b-a]" time="0.0020487308502197266"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="67" name="test_step_id_gen_mode_exact_conflict_with_param_and_fixture[b-b-b]" time="0.0020046234130859375"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="79" name="test_step_id_parametrize_mode_approx_conflict[p=a-a]" time="0.001972675323486328"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="79" name="test_step_id_parametrize_mode_approx_conflict[p=a-b]" time="0.0017435550689697266"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="79" name="test_step_id_parametrize_mode_approx_conflict[p=b-a]" time="0.0017702579498291016"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="79" name="test_step_id_parametrize_mode_approx_conflict[p=b-b]" time="0.0019006729125976562"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="88" name="test_step_id_conflicts_parametrized2[1-p=a-a]" time="0.0023338794708251953"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="88" name="test_step_id_conflicts_parametrized2[1-p=a-b]" time="0.002040386199951172"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="88" name="test_step_id_conflicts_parametrized2[1-p=b-a]" time="0.0020112991333007812"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="88" name="test_step_id_conflicts_parametrized2[1-p=b-b]" time="0.0017626285552978516"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="97" name="test_step_id_conflicts_parametrized3[b-p=a-a]" time="0.0018219947814941406"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="97" name="test_step_id_conflicts_parametrized3[b-p=a-b]" time="0.002082347869873047"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="97" name="test_step_id_conflicts_parametrized3[b-p=b-a]" time="0.0021600723266601562"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="97" name="test_step_id_conflicts_parametrized3[b-p=b-b]" time="0.0022592544555664062"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[A-1-train]" time="0.0028738975524902344"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[A-1-score]" time="0.002472400665283203"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[A-2-train]" time="0.005066394805908203"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[A-2-score]" time="0.0024673938751220703"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[B-1-train]" time="0.002272367477416992"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[B-1-score]" time="0.002554655075073242"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[B-2-train]" time="0.0025806427001953125"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[B-2-score]" time="0.0024487972259521484"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[C-1-train]" time="0.0026934146881103516"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[C-1-score]" time="0.002142190933227539"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[C-2-train]" time="0.002423524856567383"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[C-2-score]" time="0.002506256103515625"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="53" name="test_basic" time="0.0011603832244873047"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="58" name="test_synthesis" time="0.039163827896118164"><system-out>test_id                   algo_param  dataset_param    dataset        train/status      train/duration_ms  score/status      score/duration_ms    score/accuracy  -/status      -/duration_ms
----------------------  ------------  ---------------  -------------  --------------  -------------------  --------------  -------------------  ----------------  ----------  ---------------
test_my_app_bench[A-1]             1  A                my dataset #A  passed                     0.825167  passed                     0.48995          0.0415188  nan              nan
test_my_app_bench[A-2]             2  A                my dataset #A  passed                     0.377655  passed                     0.561237         0.923793   nan              nan
test_my_app_bench[B-1]             1  B                my dataset #B  passed                     0.504017  passed                     0.552654         0.120463   nan              nan
test_my_app_bench[B-2]             2  B                my dataset #B  passed                     0.55933   passed                     0.530481         0.0177752  nan              nan
test_my_app_bench[C-1]             1  C                my dataset #C  passed                     0.571728  passed                     0.469685         0.752068   nan              nan
test_my_app_bench[C-2]             2  C                my dataset #C  passed                     0.528812  passed                     0.533581         0.669051   nan              nan
test_basic                       nan  nan              nan            nan                      nan         nan                      nan              nan          passed             0.364542
</system-out></testcase></testsuite>