<?xml version="1.0" encoding="utf-8"?><testsuite errors="0" failures="0" name="pytest" skips="0" tests="84" time="2.212"><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_wrapped_in_class.py]" time="0.06778645515441895"><system-out>
Testing that running pytest on file test_wrapped_in_class.py results in {&apos;skipped&apos;: 0, &apos;failed&apos;: 0, &apos;passed&apos;: 1}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.8.0, pluggy-0.9.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests0, inifile:
plugins: steps-1.5.5.dev9+g2a8b729, metadata-1.8.0, html-1.20.0, harvest-1.6.1, faulthandler-1.5.0, cov-2.6.0
collected 1 item

test_run_all_tests.py .                                                  [100%]

=========================== 1 passed in 0.02 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_parammode_with_results_complex.py]" time="0.10578632354736328"><system-out>
Testing that running pytest on file test_steps_parammode_with_results_complex.py results in {&apos;skipped&apos;: 0, &apos;failed&apos;: 0, &apos;passed&apos;: 16}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.8.0, pluggy-0.9.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests1, inifile:
plugins: steps-1.5.5.dev9+g2a8b729, metadata-1.8.0, html-1.20.0, harvest-1.6.1, faulthandler-1.5.0, cov-2.6.0
collected 16 items

test_run_all_tests.py ................                                   [100%]

========================== 16 passed in 0.06 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_parammode_dependencies.py]" time="0.17401552200317383"><system-out>
Testing that running pytest on file test_steps_parammode_dependencies.py results in {&apos;skipped&apos;: 1, &apos;failed&apos;: 2, &apos;passed&apos;: 4}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.8.0, pluggy-0.9.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests2, inifile:
plugins: steps-1.5.5.dev9+g2a8b729, metadata-1.8.0, html-1.20.0, harvest-1.6.1, faulthandler-1.5.0, cov-2.6.0
collected 7 items

test_run_all_tests.py .Fs..F.                                            [100%]

=================================== FAILURES ===================================
________________________ test_suite_no_results[step_b] _________________________

request = &lt;FixtureRequest for &lt;Function &apos;test_suite_no_results[step_b]&apos;&gt;&gt;
test_step = &lt;function step_b at 0x7f5d437b48c8&gt;

&gt;   ???

&lt;makefun-gen-24&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_parametrizer.py:172: in wrapped_test_function
    res = test_func(*args, **kwargs)
test_run_all_tests.py:54: in test_suite_no_results
    test_step()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def step_b():
        &quot;&quot;&quot; Step a of the test &quot;&quot;&quot;
    
        # perform this step
        print(&quot;step b&quot;)
&gt;       pytest.fail(&quot;Failed intentionally - this is normal&quot;)
E       Failed: Failed intentionally - this is normal

test_run_all_tests.py:37: Failed
----------------------------- Captured stdout call -----------------------------
step b
_____________________________ test_suite_1[step_b] _____________________________

request = &lt;FixtureRequest for &lt;Function &apos;test_suite_1[step_b]&apos;&gt;&gt;
test_step = &apos;step_b&apos;

&gt;   ???

&lt;makefun-gen-25&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_parametrizer.py:129: in wrapped_test_function
    return test_func(*args, **kwargs)
test_run_all_tests.py:83: in test_suite_1
    step_b()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def step_b():
        &quot;&quot;&quot; Step a of the test &quot;&quot;&quot;
    
        # perform this step
        print(&quot;step b&quot;)
&gt;       pytest.fail(&quot;Failed intentionally - this is normal&quot;)
E       Failed: Failed intentionally - this is normal

test_run_all_tests.py:37: Failed
----------------------------- Captured stdout call -----------------------------
step b
================ 2 failed, 4 passed, 1 skipped in 0.13 seconds =================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_parammode_no_results.py]" time="0.07105302810668945"><system-out>
Testing that running pytest on file test_steps_parammode_no_results.py results in {&apos;skipped&apos;: 0, &apos;failed&apos;: 0, &apos;passed&apos;: 4}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.8.0, pluggy-0.9.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests3, inifile:
plugins: steps-1.5.5.dev9+g2a8b729, metadata-1.8.0, html-1.20.0, harvest-1.6.1, faulthandler-1.5.0, cov-2.6.0
collected 4 items

test_run_all_tests.py ....                                               [100%]

=========================== 4 passed in 0.02 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_genmode.py]" time="0.18548178672790527"><system-out>
Testing that running pytest on file test_steps_genmode.py results in {&apos;skipped&apos;: 2, &apos;failed&apos;: 2, &apos;passed&apos;: 15}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.8.0, pluggy-0.9.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests4, inifile:
plugins: steps-1.5.5.dev9+g2a8b729, metadata-1.8.0, html-1.20.0, harvest-1.6.1, faulthandler-1.5.0, cov-2.6.0
collected 19 items

test_run_all_tests.py .....Fs.Fs.........                                [100%]

=================================== FAILURES ===================================
________________ test_suite_exception_on_mandatory_step[step_b] ________________

request = &lt;FixtureRequest for &lt;Function &apos;test_suite_exception_on_mandatory_step[step_b]&apos;&gt;&gt;
________step_name_ = &apos;step_b&apos;

&gt;   ???

&lt;makefun-gen-29&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:488: in wrapped_test_function
    steps_monitor.execute(step_name, *args, **kwargs)
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:296: in execute
    res = next(self.gen)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @test_steps(&apos;step_a&apos;, &apos;step_b&apos;, &apos;step_c&apos;)
    def test_suite_exception_on_mandatory_step():
        &quot;&quot;&quot; &quot;&quot;&quot;
    
        # Step A
        print(&quot;step a&quot;)
        assert not False  # replace with your logic
        yield &apos;step_a&apos;
    
        # Step B
        print(&quot;step b&quot;)
&gt;       pytest.fail(&quot;Failed intentionally - this is normal&quot;)  # replace with your logic
E       Failed: Failed intentionally - this is normal

test_run_all_tests.py:59: Failed
----------------------------- Captured stdout call -----------------------------
step b
_______________ test_suite_optional_and_dependent_steps[step_b] ________________

request = &lt;FixtureRequest for &lt;Function &apos;test_suite_optional_and_dependent_steps[step_b]&apos;&gt;&gt;
________step_name_ = &apos;step_b&apos;

&gt;   ???

&lt;makefun-gen-30&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:488: in wrapped_test_function
    steps_monitor.execute(step_name, *args, **kwargs)
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:318: in execute
    reraise(res.exec_result.exc_type, res.exec_result.exc_val, res.exec_result.tb)
/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/six.py:693: in reraise
    raise value
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @test_steps(&apos;step_a&apos;, &apos;step_b&apos;, &apos;step_c&apos;, &apos;step_d&apos;)
    def test_suite_optional_and_dependent_steps():
        &quot;&quot;&quot; &quot;&quot;&quot;
    
        # Step A
        print(&quot;step a&quot;)
        assert not False
        yield &apos;step_a&apos;
    
        # Step B
        with optional_step(&apos;step_b&apos;) as step_b:
            print(&quot;step b&quot;)
&gt;           pytest.fail(&quot;Failed intentionally - this is normal&quot;)
E           Failed: Failed intentionally - this is normal

test_run_all_tests.py:80: Failed
----------------------------- Captured stdout call -----------------------------
step b
================ 2 failed, 15 passed, 2 skipped in 0.14 seconds ================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_parammode_stackoverflow2.py]" time="0.06884098052978516"><system-out>
Testing that running pytest on file test_steps_parammode_stackoverflow2.py results in {&apos;skipped&apos;: 0, &apos;failed&apos;: 0, &apos;passed&apos;: 3}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.8.0, pluggy-0.9.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests5, inifile:
plugins: steps-1.5.5.dev9+g2a8b729, metadata-1.8.0, html-1.20.0, harvest-1.6.1, faulthandler-1.5.0, cov-2.6.0
collected 3 items

test_run_all_tests.py ...                                                [100%]

=========================== 3 passed in 0.02 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_parammode_with_results_basic.py]" time="0.07196784019470215"><system-out>
Testing that running pytest on file test_steps_parammode_with_results_basic.py results in {&apos;skipped&apos;: 0, &apos;failed&apos;: 0, &apos;passed&apos;: 4}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.8.0, pluggy-0.9.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests6, inifile:
plugins: steps-1.5.5.dev9+g2a8b729, metadata-1.8.0, html-1.20.0, harvest-1.6.1, faulthandler-1.5.0, cov-2.6.0
collected 4 items

test_run_all_tests.py ....                                               [100%]

=========================== 4 passed in 0.02 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_genmode_does_not_change_order.py]" time="0.07608509063720703"><system-out>
Testing that running pytest on file test_steps_genmode_does_not_change_order.py results in {&apos;skipped&apos;: 0, &apos;failed&apos;: 0, &apos;passed&apos;: 5}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.8.0, pluggy-0.9.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests7, inifile:
plugins: steps-1.5.5.dev9+g2a8b729, metadata-1.8.0, html-1.20.0, harvest-1.6.1, faulthandler-1.5.0, cov-2.6.0
collected 5 items

test_run_all_tests.py .....                                              [100%]

=========================== 5 passed in 0.03 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_parammode_stackoverflow.py]" time="0.07063841819763184"><system-out>
Testing that running pytest on file test_steps_parammode_stackoverflow.py results in {&apos;skipped&apos;: 0, &apos;failed&apos;: 0, &apos;passed&apos;: 3}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.8.0, pluggy-0.9.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests8, inifile:
plugins: steps-1.5.5.dev9+g2a8b729, metadata-1.8.0, html-1.20.0, harvest-1.6.1, faulthandler-1.5.0, cov-2.6.0
collected 3 items

test_run_all_tests.py ...                                                [100%]

=========================== 3 passed in 0.02 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_pytest_parametrization_capabilities.py]" time="0.10624456405639648"><system-out>
Testing that running pytest on file test_pytest_parametrization_capabilities.py results in {&apos;skipped&apos;: 0, &apos;failed&apos;: 0, &apos;passed&apos;: 16}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.8.0, pluggy-0.9.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests9, inifile:
plugins: steps-1.5.5.dev9+g2a8b729, metadata-1.8.0, html-1.20.0, harvest-1.6.1, faulthandler-1.5.0, cov-2.6.0
collected 16 items

test_run_all_tests.py ................                                   [100%]

========================== 16 passed in 0.06 seconds ===========================
</system-out></testcase><testcase classname="pytest_steps.tests.test_all" file="pytest_steps/tests/test_all.py" line="21" name="test_run_all_tests[test_steps_genmode_dependency_tree.py]" time="0.1193230152130127"><system-out>
Testing that running pytest on file test_steps_genmode_dependency_tree.py results in {&apos;skipped&apos;: 5, &apos;failed&apos;: 1, &apos;passed&apos;: 8}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.8.0, pluggy-0.9.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests10, inifile:
plugins: steps-1.5.5.dev9+g2a8b729, metadata-1.8.0, html-1.20.0, harvest-1.6.1, faulthandler-1.5.0, cov-2.6.0
collected 14 items

test_run_all_tests.py ....Fs....ssss                                     [100%]

=================================== FAILURES ===================================
_____________________________ test_3_4[p=b-step3] ______________________________

request = &lt;FixtureRequest for &lt;Function &apos;test_3_4[p=b-step3]&apos;&gt;&gt;
________step_name_ = &apos;step3&apos;, p = &apos;b&apos;
results_dct = {&apos;step1&apos;: 1, &apos;step2&apos;: &apos;hello&apos;, &apos;step3&apos;: {&apos;a&apos;: &apos;bla&apos;, &apos;b&apos;: &apos;bla&apos;}, &apos;step4&apos;: {&apos;a&apos;: &apos;blabla&apos;}}

&gt;   ???

&lt;makefun-gen-45&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:488: in wrapped_test_function
    steps_monitor.execute(step_name, *args, **kwargs)
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:296: in execute
    res = next(self.gen)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

p = &apos;b&apos;
results_dct = {&apos;step1&apos;: 1, &apos;step2&apos;: &apos;hello&apos;, &apos;step3&apos;: {&apos;a&apos;: &apos;bla&apos;, &apos;b&apos;: &apos;bla&apos;}, &apos;step4&apos;: {&apos;a&apos;: &apos;blabla&apos;}}

    @test_steps(&apos;step3&apos;, &apos;step4&apos;)
    @pytest.mark.parametrize(&apos;p&apos;, [&apos;a&apos;, &apos;b&apos;], ids=&quot;p={}&quot;.format)
    def test_3_4(p, results_dct):
        if &apos;step2&apos; not in results_dct:
            pytest.skip(&quot;Can not start step 3: step 2 has not run successfuly&quot;)
        # step 3
        results_dct.setdefault(&apos;step3&apos;, dict())[p] = &apos;bla&apos;
        if p == &apos;b&apos;:
&gt;           pytest.fail(&quot;Failed intentionally - this is normal&quot;)
E           Failed: Failed intentionally - this is normal

test_run_all_tests.py:33: Failed
================ 1 failed, 8 passed, 5 skipped in 0.07 seconds =================
</system-out></testcase><testcase classname="pytest_steps.tests.test_cross_steps_fixture" file="pytest_steps/tests/test_cross_steps_fixture.py" line="17" name="test_gen_mode[0-a]" time="0.0017826557159423828"><system-out>hello
</system-out></testcase><testcase classname="pytest_steps.tests.test_cross_steps_fixture" file="pytest_steps/tests/test_cross_steps_fixture.py" line="17" name="test_gen_mode[0-b]" time="0.0018429756164550781"><system-out>world
</system-out></testcase><testcase classname="pytest_steps.tests.test_cross_steps_fixture" file="pytest_steps/tests/test_cross_steps_fixture.py" line="34" name="test_params_mode[0-step_a]" time="0.0016603469848632812"><system-out>hello
</system-out></testcase><testcase classname="pytest_steps.tests.test_cross_steps_fixture" file="pytest_steps/tests/test_cross_steps_fixture.py" line="34" name="test_params_mode[0-step_b]" time="0.0014808177947998047"><system-out>world
</system-out></testcase><testcase classname="pytest_steps.tests.test_cross_steps_fixture" file="pytest_steps/tests/test_cross_steps_fixture.py" line="40" name="test_fixture_has_been_called_once_per_fun" time="0.001367807388305664"></testcase><testcase classname="pytest_steps.tests.test_docs_example_manual_call" file="pytest_steps/tests/test_docs_example_manual_call.py" line="5" name="test_dummy_gen[first]" time="0.0015320777893066406"><system-out>hello
</system-out></testcase><testcase classname="pytest_steps.tests.test_docs_example_manual_call" file="pytest_steps/tests/test_docs_example_manual_call.py" line="5" name="test_dummy_gen[second]" time="0.0014722347259521484"><system-out>world
</system-out></testcase><testcase classname="pytest_steps.tests.test_docs_example_manual_call" file="pytest_steps/tests/test_docs_example_manual_call.py" line="22" name="test_dummy_param_deps[first]" time="0.0014281272888183594"><system-out>hello
</system-out></testcase><testcase classname="pytest_steps.tests.test_docs_example_manual_call" file="pytest_steps/tests/test_docs_example_manual_call.py" line="22" name="test_dummy_param_deps[second]" time="0.0014574527740478516"><system-out>world
</system-out></testcase><testcase classname="pytest_steps.tests.test_docs_example_manual_call" file="pytest_steps/tests/test_docs_example_manual_call.py" line="27" name="test_dummy_param[first]" time="0.0012166500091552734"><system-out>hello
</system-out></testcase><testcase classname="pytest_steps.tests.test_docs_example_manual_call" file="pytest_steps/tests/test_docs_example_manual_call.py" line="27" name="test_dummy_param[second]" time="0.0013616085052490234"><system-out>world
</system-out></testcase><testcase classname="pytest_steps.tests.test_docs_example_manual_call" file="pytest_steps/tests/test_docs_example_manual_call.py" line="35" name="test_manual_call[test_dummy_gen]" time="0.005894660949707031"><system-out>Help on function test_dummy_gen in module pytest_steps.tests.test_docs_example_manual_call:

test_dummy_gen(request, ________step_name_)

None
hello
world
hello
hello
world
</system-out></testcase><testcase classname="pytest_steps.tests.test_docs_example_manual_call" file="pytest_steps/tests/test_docs_example_manual_call.py" line="35" name="test_manual_call[test_dummy_param_deps]" time="0.0021619796752929688"><system-out>Help on function test_dummy_param_deps in module pytest_steps.tests.test_docs_example_manual_call:

test_dummy_param_deps(request, test_step)
    Executes the current step only if its dependencies are correct, and registers its execution result

None
hello
world
hello
hello
world
world
</system-out></testcase><testcase classname="pytest_steps.tests.test_docs_example_manual_call" file="pytest_steps/tests/test_docs_example_manual_call.py" line="35" name="test_manual_call[test_dummy_param]" time="0.0020525455474853516"><system-out>Help on function test_dummy_param in module pytest_steps.tests.test_docs_example_manual_call:

test_dummy_param(request, test_step)

None
hello
world
hello
hello
world
world
</system-out></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[A-1-train]" time="0.0028297901153564453"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[A-1-score]" time="0.0022580623626708984"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[A-2-train]" time="0.0022344589233398438"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[A-2-score]" time="0.0021240711212158203"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[B-1-train]" time="0.0022192001342773438"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[B-1-score]" time="0.0020520687103271484"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[B-2-train]" time="0.0020394325256347656"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[B-2-score]" time="0.002154827117919922"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[C-1-train]" time="0.0023620128631591797"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[C-1-score]" time="0.0021140575408935547"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[C-2-train]" time="0.0021665096282958984"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="32" name="test_my_app_bench[C-2-score]" time="0.0019237995147705078"></testcase><testcase classname="pytest_steps.tests.test_docs_example_with_harvest" file="pytest_steps/tests/test_docs_example_with_harvest.py" line="53" name="test_synthesis_df" time="0.09926366806030273"><system-out>
   `module_results_df` dataframe:

                                status    ...     accuracy
test_id                step_id            ...             
test_my_app_bench[A-1] train    passed    ...     0.967874
                       score    passed    ...          NaN
test_my_app_bench[A-2] train    passed    ...     0.721997
                       score    passed    ...          NaN
test_my_app_bench[B-1] train    passed    ...     0.168594
                       score    passed    ...          NaN
test_my_app_bench[B-2] train    passed    ...     0.816325
                       score    passed    ...          NaN
test_my_app_bench[C-1] train    passed    ...     0.773256
                       score    passed    ...          NaN
test_my_app_bench[C-2] train    passed    ...     0.380152
                       score    passed    ...          NaN

[12 rows x 6 columns]
                                     status      duration_ms    algo_param  dataset_param    dataset          accuracy
-----------------------------------  --------  -------------  ------------  ---------------  -------------  ----------
(&apos;test_my_app_bench[A-1]&apos;, &apos;train&apos;)  passed         0.41461              1  A                my dataset #A    0.967874
(&apos;test_my_app_bench[A-1]&apos;, &apos;score&apos;)  passed         0.460386             1  A                my dataset #A  nan
(&apos;test_my_app_bench[A-2]&apos;, &apos;train&apos;)  passed         0.498772             2  A                my dataset #A    0.721997
(&apos;test_my_app_bench[A-2]&apos;, &apos;score&apos;)  passed         0.446558             2  A                my dataset #A  nan
(&apos;test_my_app_bench[B-1]&apos;, &apos;train&apos;)  passed         0.470877             1  B                my dataset #B    0.168594
(&apos;test_my_app_bench[B-1]&apos;, &apos;score&apos;)  passed         0.39053              1  B                my dataset #B  nan
(&apos;test_my_app_bench[B-2]&apos;, &apos;train&apos;)  passed         0.395775             2  B                my dataset #B    0.816325
(&apos;test_my_app_bench[B-2]&apos;, &apos;score&apos;)  passed         0.450134             2  B                my dataset #B  nan
(&apos;test_my_app_bench[C-1]&apos;, &apos;train&apos;)  passed         0.645638             1  C                my dataset #C    0.773256
(&apos;test_my_app_bench[C-1]&apos;, &apos;score&apos;)  passed         0.431299             1  C                my dataset #C  nan
(&apos;test_my_app_bench[C-2]&apos;, &apos;train&apos;)  passed         0.455618             2  C                my dataset #C    0.380152
(&apos;test_my_app_bench[C-2]&apos;, &apos;score&apos;)  passed         0.377893             2  C                my dataset #C  nan

   `module_results_df_steps_pivoted` dataframe:

                        algo_param      ...        score/dataset
test_id                                 ...                     
test_my_app_bench[A-1]           1      ...        my dataset #A
test_my_app_bench[A-2]           2      ...        my dataset #A
test_my_app_bench[B-1]           1      ...        my dataset #B
test_my_app_bench[B-2]           2      ...        my dataset #B
test_my_app_bench[C-1]           1      ...        my dataset #C
test_my_app_bench[C-2]           2      ...        my dataset #C

[6 rows x 9 columns]
test_id                   algo_param  dataset_param    train/status      train/duration_ms  train/dataset      train/accuracy  score/status      score/duration_ms  score/dataset
----------------------  ------------  ---------------  --------------  -------------------  ---------------  ----------------  --------------  -------------------  ---------------
test_my_app_bench[A-1]             1  A                passed                     0.41461   my dataset #A            0.967874  passed                     0.460386  my dataset #A
test_my_app_bench[A-2]             2  A                passed                     0.498772  my dataset #A            0.721997  passed                     0.446558  my dataset #A
test_my_app_bench[B-1]             1  B                passed                     0.470877  my dataset #B            0.168594  passed                     0.39053   my dataset #B
test_my_app_bench[B-2]             2  B                passed                     0.395775  my dataset #B            0.816325  passed                     0.450134  my dataset #B
test_my_app_bench[C-1]             1  C                passed                     0.645638  my dataset #C            0.773256  passed                     0.431299  my dataset #C
test_my_app_bench[C-2]             2  C                passed                     0.455618  my dataset #C            0.380152  passed                     0.377893  my dataset #C
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="26" name="test_step_id_gen_mode_approx_conflict_params[p=a-a]" time="0.0018324851989746094"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="26" name="test_step_id_gen_mode_approx_conflict_params[p=a-b]" time="0.0017237663269042969"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="26" name="test_step_id_gen_mode_approx_conflict_params[p=b-a]" time="0.0016145706176757812"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="26" name="test_step_id_gen_mode_approx_conflict_params[p=b-b]" time="0.0016117095947265625"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="33" name="test_step_id_gen_mode_approx_conflict_fixture[hello-b-foo-a]" time="0.0017435550689697266"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="33" name="test_step_id_gen_mode_approx_conflict_fixture[hello-b-foo-b]" time="0.0016489028930664062"></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="39" name="test_step_id_gen_mode_approx_conflict_params_and_no_conflict_fixture[1-p=a-a]" time="0.0023584365844726562"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="39" name="test_step_id_gen_mode_approx_conflict_params_and_no_conflict_fixture[1-p=a-b]" time="0.0018737316131591797"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="39" name="test_step_id_gen_mode_approx_conflict_params_and_no_conflict_fixture[1-p=b-a]" time="0.0016465187072753906"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="39" name="test_step_id_gen_mode_approx_conflict_params_and_no_conflict_fixture[1-p=b-b]" time="0.0018696784973144531"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="50" name="test_step_id_gen_mode_exact_conflict_with_param[a-a]" time="0.0017743110656738281"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="50" name="test_step_id_gen_mode_exact_conflict_with_param[a-b]" time="0.0017566680908203125"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="50" name="test_step_id_gen_mode_exact_conflict_with_param[b-a]" time="0.0017879009246826172"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="50" name="test_step_id_gen_mode_exact_conflict_with_param[b-b]" time="0.001779794692993164"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="59" name="test_step_id_gen_mode_exact_conflict_with_fixture[b-a]" time="0.0014507770538330078"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="59" name="test_step_id_gen_mode_exact_conflict_with_fixture[b-b]" time="0.001941680908203125"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="67" name="test_step_id_gen_mode_exact_conflict_with_param_and_fixture[b-a-a]" time="0.0018453598022460938"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="67" name="test_step_id_gen_mode_exact_conflict_with_param_and_fixture[b-a-b]" time="0.0018572807312011719"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="67" name="test_step_id_gen_mode_exact_conflict_with_param_and_fixture[b-b-a]" time="0.0018458366394042969"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="67" name="test_step_id_gen_mode_exact_conflict_with_param_and_fixture[b-b-b]" time="0.001844167709350586"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="79" name="test_step_id_parametrize_mode_approx_conflict[p=a-a]" time="0.0015583038330078125"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="79" name="test_step_id_parametrize_mode_approx_conflict[p=a-b]" time="0.0017561912536621094"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="79" name="test_step_id_parametrize_mode_approx_conflict[p=b-a]" time="0.0017981529235839844"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="79" name="test_step_id_parametrize_mode_approx_conflict[p=b-b]" time="0.001800537109375"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="88" name="test_step_id_conflicts_parametrized2[1-p=a-a]" time="0.0022690296173095703"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="88" name="test_step_id_conflicts_parametrized2[1-p=a-b]" time="0.001984119415283203"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="88" name="test_step_id_conflicts_parametrized2[1-p=b-a]" time="0.0017399787902832031"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="88" name="test_step_id_conflicts_parametrized2[1-p=b-b]" time="0.0018646717071533203"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="97" name="test_step_id_conflicts_parametrized3[b-p=a-a]" time="0.0020792484283447266"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="97" name="test_step_id_conflicts_parametrized3[b-p=a-b]" time="0.001968860626220703"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="97" name="test_step_id_conflicts_parametrized3[b-p=b-a]" time="0.0019643306732177734"><system-out>a
</system-out></testcase><testcase classname="pytest_steps.tests.test_step_id_conflicts" file="pytest_steps/tests/test_step_id_conflicts.py" line="97" name="test_step_id_conflicts_parametrized3[b-p=b-b]" time="0.0019979476928710938"><system-out>b
</system-out></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[A-1-train]" time="0.0021567344665527344"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[A-1-score]" time="0.004282474517822266"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[A-2-train]" time="0.002203702926635742"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[A-2-score]" time="0.002179384231567383"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[B-1-train]" time="0.0022172927856445312"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[B-1-score]" time="0.0018987655639648438"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[B-2-train]" time="0.002173900604248047"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[B-2-score]" time="0.002153635025024414"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[C-1-train]" time="0.0021963119506835938"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[C-1-score]" time="0.0022001266479492188"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[C-2-train]" time="0.0023980140686035156"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="32" name="test_my_app_bench[C-2-score]" time="0.0019042491912841797"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="53" name="test_basic" time="0.0010821819305419922"></testcase><testcase classname="pytest_steps.tests.test_steps_harvest" file="pytest_steps/tests/test_steps_harvest.py" line="58" name="test_synthesis" time="0.06867146492004395"><system-out>test_id                   algo_param  dataset_param    train/status      train/duration_ms  train/dataset      train/accuracy  score/status      score/duration_ms  score/dataset    -/status      -/duration_ms
----------------------  ------------  ---------------  --------------  -------------------  ---------------  ----------------  --------------  -------------------  ---------------  ----------  ---------------
test_my_app_bench[A-1]             1  A                passed                     0.499249  my dataset #A            0.772596  passed                     0.48089   my dataset #A    nan              nan
test_my_app_bench[A-2]             2  A                passed                     0.465393  my dataset #A            0.803366  passed                     0.449896  my dataset #A    nan              nan
test_my_app_bench[B-1]             1  B                passed                     0.490904  my dataset #B            0.485178  passed                     0.410318  my dataset #B    nan              nan
test_my_app_bench[B-2]             2  B                passed                     0.484705  my dataset #B            0.258074  passed                     0.43416   my dataset #B    nan              nan
test_my_app_bench[C-1]             1  C                passed                     0.469208  my dataset #C            0.587036  passed                     0.437975  my dataset #C    nan              nan
test_my_app_bench[C-2]             2  C                passed                     0.448465  my dataset #C            0.431067  passed                     0.383139  my dataset #C    nan              nan
test_basic                       nan  nan              nan                      nan         nan                    nan         nan                      nan         nan              passed             0.349522
</system-out></testcase></testsuite>