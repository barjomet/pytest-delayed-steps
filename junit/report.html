<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <title>Test Report</title>
    <link href="assets/style.css" rel="stylesheet" type="text/css"/></head>
  <body onLoad="init()">
    <script>/* This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this file,
 * You can obtain one at http://mozilla.org/MPL/2.0/. */


function toArray(iter) {
    if (iter === null) {
        return null;
    }
    return Array.prototype.slice.call(iter);
}

function find(selector, elem) {
    if (!elem) {
        elem = document;
    }
    return elem.querySelector(selector);
}

function find_all(selector, elem) {
    if (!elem) {
        elem = document;
    }
    return toArray(elem.querySelectorAll(selector));
}

function sort_column(elem) {
    toggle_sort_states(elem);
    var colIndex = toArray(elem.parentNode.childNodes).indexOf(elem);
    var key;
    if (elem.classList.contains('numeric')) {
        key = key_num;
    } else if (elem.classList.contains('result')) {
        key = key_result;
    } else {
        key = key_alpha;
    }
    sort_table(elem, key(colIndex));
}

function show_all_extras() {
    find_all('.col-result').forEach(show_extras);
}

function hide_all_extras() {
    find_all('.col-result').forEach(hide_extras);
}

function show_extras(colresult_elem) {
    var extras = colresult_elem.parentNode.nextElementSibling;
    var expandcollapse = colresult_elem.firstElementChild;
    extras.classList.remove("collapsed");
    expandcollapse.classList.remove("expander");
    expandcollapse.classList.add("collapser");
}

function hide_extras(colresult_elem) {
    var extras = colresult_elem.parentNode.nextElementSibling;
    var expandcollapse = colresult_elem.firstElementChild;
    extras.classList.add("collapsed");
    expandcollapse.classList.remove("collapser");
    expandcollapse.classList.add("expander");
}

function show_filters() {
    var filter_items = document.getElementsByClassName('filter');
    for (var i = 0; i < filter_items.length; i++)
        filter_items[i].hidden = false;
}

function add_collapse() {
    // Add links for show/hide all
    var resulttable = find('table#results-table');
    var showhideall = document.createElement("p");
    showhideall.innerHTML = '<a href="javascript:show_all_extras()">Show all details</a> / ' +
                            '<a href="javascript:hide_all_extras()">Hide all details</a>';
    resulttable.parentElement.insertBefore(showhideall, resulttable);

    // Add show/hide link to each result
    find_all('.col-result').forEach(function(elem) {
        var collapsed = get_query_parameter('collapsed') || 'Passed';
        var extras = elem.parentNode.nextElementSibling;
        var expandcollapse = document.createElement("span");
        if (collapsed.includes(elem.innerHTML)) {
            extras.classList.add("collapsed");
            expandcollapse.classList.add("expander");
        } else {
            expandcollapse.classList.add("collapser");
        }
        elem.appendChild(expandcollapse);

        elem.addEventListener("click", function(event) {
            if (event.currentTarget.parentNode.nextElementSibling.classList.contains("collapsed")) {
                show_extras(event.currentTarget);
            } else {
                hide_extras(event.currentTarget);
            }
        });
    })
}

function get_query_parameter(name) {
    var match = RegExp('[?&]' + name + '=([^&]*)').exec(window.location.search);
    return match && decodeURIComponent(match[1].replace(/\+/g, ' '));
}

function init () {
    reset_sort_headers();

    add_collapse();

    show_filters();

    toggle_sort_states(find('.initial-sort'));

    find_all('.sortable').forEach(function(elem) {
        elem.addEventListener("click",
                              function(event) {
                                  sort_column(elem);
                              }, false)
    });

};

function sort_table(clicked, key_func) {
    var rows = find_all('.results-table-row');
    var reversed = !clicked.classList.contains('asc');
    var sorted_rows = sort(rows, key_func, reversed);
    /* Whole table is removed here because browsers acts much slower
     * when appending existing elements.
     */
    var thead = document.getElementById("results-table-head");
    document.getElementById('results-table').remove();
    var parent = document.createElement("table");
    parent.id = "results-table";
    parent.appendChild(thead);
    sorted_rows.forEach(function(elem) {
        parent.appendChild(elem);
    });
    document.getElementsByTagName("BODY")[0].appendChild(parent);
}

function sort(items, key_func, reversed) {
    var sort_array = items.map(function(item, i) {
        return [key_func(item), i];
    });
    var multiplier = reversed ? -1 : 1;

    sort_array.sort(function(a, b) {
        var key_a = a[0];
        var key_b = b[0];
        return multiplier * (key_a >= key_b ? 1 : -1);
    });

    return sort_array.map(function(item) {
        var index = item[1];
        return items[index];
    });
}

function key_alpha(col_index) {
    return function(elem) {
        return elem.childNodes[1].childNodes[col_index].firstChild.data.toLowerCase();
    };
}

function key_num(col_index) {
    return function(elem) {
        return parseFloat(elem.childNodes[1].childNodes[col_index].firstChild.data);
    };
}

function key_result(col_index) {
    return function(elem) {
        var strings = ['Error', 'Failed', 'Rerun', 'XFailed', 'XPassed',
                       'Skipped', 'Passed'];
        return strings.indexOf(elem.childNodes[1].childNodes[col_index].firstChild.data);
    };
}

function reset_sort_headers() {
    find_all('.sort-icon').forEach(function(elem) {
        elem.parentNode.removeChild(elem);
    });
    find_all('.sortable').forEach(function(elem) {
        var icon = document.createElement("div");
        icon.className = "sort-icon";
        icon.textContent = "vvv";
        elem.insertBefore(icon, elem.firstChild);
        elem.classList.remove("desc", "active");
        elem.classList.add("asc", "inactive");
    });
}

function toggle_sort_states(elem) {
    //if active, toggle between asc and desc
    if (elem.classList.contains('active')) {
        elem.classList.toggle('asc');
        elem.classList.toggle('desc');
    }

    //if inactive, reset all other functions and add ascending active
    if (elem.classList.contains('inactive')) {
        reset_sort_headers();
        elem.classList.remove('inactive');
        elem.classList.add('active');
    }
}

function is_all_rows_hidden(value) {
  return value.hidden == false;
}

function filter_table(elem) {
    var outcome_att = "data-test-result";
    var outcome = elem.getAttribute(outcome_att);
    class_outcome = outcome + " results-table-row";
    var outcome_rows = document.getElementsByClassName(class_outcome);

    for(var i = 0; i < outcome_rows.length; i++){
        outcome_rows[i].hidden = !elem.checked;
    }

    var rows = find_all('.results-table-row').filter(is_all_rows_hidden);
    var all_rows_hidden = rows.length == 0 ? true : false;
    var not_found_message = document.getElementById("not-found-message");
    not_found_message.hidden = !all_rows_hidden;
}
</script>
    <h1>report.html</h1>
    <p>Report generated on 21-Nov-2018 at 15:07:14 by<a href="https://pypi.python.org/pypi/pytest-html"> pytest-html</a> v1.19.0</p>
    <h2>Environment</h2>
    <table id="environment">
      <tr>
        <td>CI</td>
        <td>true</td></tr>
      <tr>
        <td>JAVA_HOME</td>
        <td>/usr/lib/jvm/java-8-oracle</td></tr>
      <tr>
        <td>Packages</td>
        <td>{&apos;pytest&apos;: &apos;3.10.1&apos;, &apos;py&apos;: &apos;1.7.0&apos;, &apos;pluggy&apos;: &apos;0.8.0&apos;}</td></tr>
      <tr>
        <td>Platform</td>
        <td>Linux-4.4.0-101-generic-x86_64-with-debian-jessie-sid</td></tr>
      <tr>
        <td>Plugins</td>
        <td>{&apos;metadata&apos;: &apos;1.7.0&apos;, &apos;harvest&apos;: &apos;1.0.1&apos;, &apos;html&apos;: &apos;1.19.0&apos;, &apos;cov&apos;: &apos;2.6.0&apos;, &apos;faulthandler&apos;: &apos;1.5.0&apos;}</td></tr>
      <tr>
        <td>Python</td>
        <td>3.5.6</td></tr>
      <tr>
        <td>TRAVIS_BRANCH</td>
        <td>1.1.2</td></tr>
      <tr>
        <td>TRAVIS_BUILD_ID</td>
        <td>457980472</td></tr>
      <tr>
        <td>TRAVIS_BUILD_NUMBER</td>
        <td>73</td></tr>
      <tr>
        <td>TRAVIS_COMMIT</td>
        <td>02d167aaf43acd41c093ff366e565b1112f26baa</td></tr>
      <tr>
        <td>TRAVIS_COMMIT_MESSAGE</td>
        <td>1.1.2 changelog</td></tr>
      <tr>
        <td>TRAVIS_EVENT_TYPE</td>
        <td>push</td></tr>
      <tr>
        <td>TRAVIS_JOB_ID</td>
        <td>457980477</td></tr>
      <tr>
        <td>TRAVIS_JOB_NUMBER</td>
        <td>73.5</td></tr>
      <tr>
        <td>TRAVIS_OS_NAME</td>
        <td>linux</td></tr>
      <tr>
        <td>TRAVIS_PULL_REQUEST</td>
        <td>false</td></tr>
      <tr>
        <td>TRAVIS_REPO_SLUG</td>
        <td>smarie/python-pytest-steps</td></tr>
      <tr>
        <td>TRAVIS_SUDO</td>
        <td>true</td></tr>
      <tr>
        <td>TRAVIS_TAG</td>
        <td>1.1.2</td></tr></table>
    <h2>Summary</h2>
    <p>41 tests ran in 1.79 seconds. </p>
    <p class="filter" hidden="true">(Un)check the boxes to filter the results.</p><input checked="true" class="filter" data-test-result="passed" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="passed">41 passed</span>, <input checked="true" class="filter" data-test-result="skipped" disabled="true" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="skipped">0 skipped</span>, <input checked="true" class="filter" data-test-result="failed" disabled="true" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="failed">0 failed</span>, <input checked="true" class="filter" data-test-result="error" disabled="true" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="error">0 errors</span>, <input checked="true" class="filter" data-test-result="xfailed" disabled="true" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="xfailed">0 expected failures</span>, <input checked="true" class="filter" data-test-result="xpassed" disabled="true" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="xpassed">0 unexpected passes</span>
    <h2>Results</h2>
    <table id="results-table">
      <thead id="results-table-head">
        <tr>
          <th class="sortable result initial-sort" col="result">Result</th>
          <th class="sortable" col="name">Test</th>
          <th class="sortable numeric" col="duration">Duration</th>
          <th>Links</th></tr>
        <tr hidden="true" id="not-found-message">
          <th colspan="4">No results found. Try to check the filters</th></tr></thead>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_all.py::test_run_all_tests[test_steps_with_results_complex.py]</td>
          <td class="col-duration">0.10</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">----------------------------- Captured stdout call -----------------------------<br/>
Testing that running pytest on file test_steps_with_results_complex.py results in {&#x27;skipped&#x27;: 0, &#x27;passed&#x27;: 16, &#x27;failed&#x27;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests0, inifile:
plugins: metadata-1.7.0, html-1.19.0, harvest-1.0.1, faulthandler-1.5.0, cov-2.6.0
collected 16 items

test_run_all_tests.py ................                                   [100%]

========================== 16 passed in 0.06 seconds ===========================
</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_all.py::test_run_all_tests[test_steps_generator_does_not_change_order.py]</td>
          <td class="col-duration">0.07</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">----------------------------- Captured stdout call -----------------------------<br/>
Testing that running pytest on file test_steps_generator_does_not_change_order.py results in {&#x27;skipped&#x27;: 0, &#x27;passed&#x27;: 3, &#x27;failed&#x27;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests1, inifile:
plugins: metadata-1.7.0, html-1.19.0, harvest-1.0.1, faulthandler-1.5.0, cov-2.6.0
collected 3 items

test_run_all_tests.py ...                                                [100%]

=============================== warnings summary ===============================
test_run_all_tests.py::test_synthesis
  /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest_harvest/results_session.py:341: UserWarning: [pytest-harvest] Test items status is not available. You should maybe install pytest-harvest with pip. If it is already the case, you case try to force-use it by adding `pytest_plugins = [&#x27;harvest&#x27;]` to your conftest.py. But for normal use this should not be required, installing with pip should be enough.
    warn(&quot;[pytest-harvest] Test items status is not available. You should maybe install pytest-harvest with &quot;

-- Docs: https://docs.pytest.org/en/latest/warnings.html
===================== 3 passed, 1 warnings in 0.02 seconds =====================
</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_all.py::test_run_all_tests[test_wrapped_in_class.py]</td>
          <td class="col-duration">0.06</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">----------------------------- Captured stdout call -----------------------------<br/>
Testing that running pytest on file test_wrapped_in_class.py results in {&#x27;skipped&#x27;: 0, &#x27;passed&#x27;: 1, &#x27;failed&#x27;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests2, inifile:
plugins: metadata-1.7.0, html-1.19.0, harvest-1.0.1, faulthandler-1.5.0, cov-2.6.0
collected 1 item

test_run_all_tests.py .                                                  [100%]

=========================== 1 passed in 0.02 seconds ===========================
</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_all.py::test_run_all_tests[test_stackoverflow.py]</td>
          <td class="col-duration">0.10</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">----------------------------- Captured stdout call -----------------------------<br/>
Testing that running pytest on file test_stackoverflow.py results in {&#x27;skipped&#x27;: 0, &#x27;passed&#x27;: 3, &#x27;failed&#x27;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests3, inifile:
plugins: metadata-1.7.0, html-1.19.0, harvest-1.0.1, faulthandler-1.5.0, cov-2.6.0
collected 3 items

test_run_all_tests.py ...                                                [100%]

=========================== 3 passed in 0.06 seconds ===========================
</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_all.py::test_run_all_tests[test_steps_new_with_generator.py]</td>
          <td class="col-duration">0.21</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">----------------------------- Captured stdout call -----------------------------<br/>
Testing that running pytest on file test_steps_new_with_generator.py results in {&#x27;skipped&#x27;: 2, &#x27;passed&#x27;: 12, &#x27;failed&#x27;: 2}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests4, inifile:
plugins: metadata-1.7.0, html-1.19.0, harvest-1.0.1, faulthandler-1.5.0, cov-2.6.0
collected 16 items

test_run_all_tests.py ....Fs.Fs.......                                   [100%]

=================================== FAILURES ===================================
________________ test_suite_exception_on_mandatory_step[step_b] ________________

________step_name_ = &#x27;step_b&#x27;
request = &lt;FixtureRequest for &lt;Function &#x27;test_suite_exception_on_mandatory_step[step_b]&#x27;&gt;&gt;

&gt;   ???

&lt;decorator-gen-11&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/travis/build/smarie/python-pytest-steps/pytest_steps/decorator_hack.py:167: in caller
    **kwargs)
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:431: in step_function_wrapper
    steps_monitor.execute(step_name, *args, **kwargs)
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:270: in execute
    res = next(self.gen)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @test_steps(&#x27;step_a&#x27;, &#x27;step_b&#x27;, &#x27;step_c&#x27;)
    def test_suite_exception_on_mandatory_step():
        &quot;&quot;&quot; &quot;&quot;&quot;
    
        # Step A
        print(&quot;step a&quot;)
        assert not False  # replace with your logic
        yield &#x27;step_a&#x27;
    
        # Step B
        print(&quot;step b&quot;)
&gt;       assert False  # replace with your logic
E       assert False

test_run_all_tests.py:43: AssertionError
----------------------------- Captured stdout call -----------------------------
step b
_______________ test_suite_optional_and_dependent_steps[step_b] ________________

________step_name_ = &#x27;step_b&#x27;
request = &lt;FixtureRequest for &lt;Function &#x27;test_suite_optional_and_dependent_steps[step_b]&#x27;&gt;&gt;

&gt;   ???

&lt;decorator-gen-12&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/travis/build/smarie/python-pytest-steps/pytest_steps/decorator_hack.py:167: in caller
    **kwargs)
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:431: in step_function_wrapper
    steps_monitor.execute(step_name, *args, **kwargs)
/home/travis/build/smarie/python-pytest-steps/pytest_steps/steps_generator.py:292: in execute
    raise six.reraise(res.exec_result.exc_type, res.exec_result.exc_val, res.exec_result.tb)
/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/six.py:693: in reraise
    raise value
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @test_steps(&#x27;step_a&#x27;, &#x27;step_b&#x27;, &#x27;step_c&#x27;, &#x27;step_d&#x27;)
    def test_suite_optional_and_dependent_steps():
        &quot;&quot;&quot; &quot;&quot;&quot;
    
        # Step A
        print(&quot;step a&quot;)
        assert not False
        yield &#x27;step_a&#x27;
    
        # Step B
        with optional_step(&#x27;step_b&#x27;) as step_b:
            print(&quot;step b&quot;)
&gt;           assert False
E           assert False

test_run_all_tests.py:64: AssertionError
----------------------------- Captured stdout call -----------------------------
step b
================ 2 failed, 12 passed, 2 skipped in 0.17 seconds ================
</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_all.py::test_run_all_tests[test_pytest_capabilities.py]</td>
          <td class="col-duration">0.10</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">----------------------------- Captured stdout call -----------------------------<br/>
Testing that running pytest on file test_pytest_capabilities.py results in {&#x27;skipped&#x27;: 0, &#x27;passed&#x27;: 16, &#x27;failed&#x27;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests5, inifile:
plugins: metadata-1.7.0, html-1.19.0, harvest-1.0.1, faulthandler-1.5.0, cov-2.6.0
collected 16 items

test_run_all_tests.py ................                                   [100%]

========================== 16 passed in 0.05 seconds ===========================
</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_all.py::test_run_all_tests[test_steps_with_results_basic.py]</td>
          <td class="col-duration">0.07</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">----------------------------- Captured stdout call -----------------------------<br/>
Testing that running pytest on file test_steps_with_results_basic.py results in {&#x27;skipped&#x27;: 0, &#x27;passed&#x27;: 4, &#x27;failed&#x27;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests6, inifile:
plugins: metadata-1.7.0, html-1.19.0, harvest-1.0.1, faulthandler-1.5.0, cov-2.6.0
collected 4 items

test_run_all_tests.py ....                                               [100%]

=========================== 4 passed in 0.03 seconds ===========================
</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_all.py::test_run_all_tests[test_steps_no_results.py]</td>
          <td class="col-duration">0.07</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">----------------------------- Captured stdout call -----------------------------<br/>
Testing that running pytest on file test_steps_no_results.py results in {&#x27;skipped&#x27;: 0, &#x27;passed&#x27;: 4, &#x27;failed&#x27;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests7, inifile:
plugins: metadata-1.7.0, html-1.19.0, harvest-1.0.1, faulthandler-1.5.0, cov-2.6.0
collected 4 items

test_run_all_tests.py ....                                               [100%]

=========================== 4 passed in 0.02 seconds ===========================
</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_all.py::test_run_all_tests[test_steps_dependencies.py]</td>
          <td class="col-duration">0.09</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">----------------------------- Captured stdout call -----------------------------<br/>
Testing that running pytest on file test_steps_dependencies.py results in {&#x27;skipped&#x27;: 1, &#x27;passed&#x27;: 3, &#x27;failed&#x27;: 2}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests8, inifile:
plugins: metadata-1.7.0, html-1.19.0, harvest-1.0.1, faulthandler-1.5.0, cov-2.6.0
collected 6 items

test_run_all_tests.py .Fs.F.                                             [100%]

=================================== FAILURES ===================================
________________________ test_suite_no_results[step_b] _________________________

test_step = &lt;function step_b at 0x7f9fbd8619d8&gt;
request = &lt;FixtureRequest for &lt;Function &#x27;test_suite_no_results[step_b]&#x27;&gt;&gt;

    @test_steps(step_a, step_b, step_c)
    def test_suite_no_results(test_step, request):
        &quot;&quot;&quot; In this test suite, the last step will be skipped because the second step failed (and there is a dependency) &quot;&quot;&quot;
    
        # Execute the step
&gt;       test_step()

test_run_all_tests.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def step_b():
        &quot;&quot;&quot; Step a of the test &quot;&quot;&quot;
    
        # perform this step
        print(&quot;step b&quot;)
&gt;       assert False
E       assert False

test_run_all_tests.py:20: AssertionError
----------------------------- Captured stdout call -----------------------------
step b
_____________________________ test_suite_1[step_b] _____________________________

test_step = &#x27;step_b&#x27;

    @test_steps(&#x27;step_a&#x27;, &#x27;step_b&#x27;, &#x27;step_c&#x27;)
    def test_suite_1(test_step):
        &quot;&quot;&quot; In this test suite the last step can &quot;see&quot; the dependency so it is still executed ...&quot;&quot;&quot;
        # Execute the step according to name
        if test_step == &#x27;step_a&#x27;:
            step_a()
        elif test_step == &#x27;step_b&#x27;:
&gt;           step_b()

test_run_all_tests.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def step_b():
        &quot;&quot;&quot; Step a of the test &quot;&quot;&quot;
    
        # perform this step
        print(&quot;step b&quot;)
&gt;       assert False
E       assert False

test_run_all_tests.py:20: AssertionError
----------------------------- Captured stdout call -----------------------------
step b
================ 2 failed, 3 passed, 1 skipped in 0.04 seconds =================
</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_all.py::test_run_all_tests[test_stackoverflow2.py]</td>
          <td class="col-duration">0.06</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">----------------------------- Captured stdout call -----------------------------<br/>
Testing that running pytest on file test_stackoverflow2.py results in {&#x27;skipped&#x27;: 0, &#x27;passed&#x27;: 3, &#x27;failed&#x27;: 0}
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.10.1, py-1.7.0, pluggy-0.8.0
rootdir: /tmp/pytest-of-travis/pytest-0/test_run_all_tests9, inifile:
plugins: metadata-1.7.0, html-1.19.0, harvest-1.0.1, faulthandler-1.5.0, cov-2.6.0
collected 3 items

test_run_all_tests.py ...                                                [100%]

=========================== 3 passed in 0.02 seconds ===========================
</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_decorator.py::test_normal_normal</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">----------------------------- Captured stdout call -----------------------------<br/>0
1
2
3
4
5
6
7
8
9
</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_decorator.py::test_normal_gen</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">----------------------------- Captured stdout call -----------------------------<br/>0
1
2
3
4
5
6
7
8
9
</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_decorator.py::test_gen_gen</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">----------------------------- Captured stdout call -----------------------------<br/>0
</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_decorator.py::test_gen_normal</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">----------------------------- Captured stdout call -----------------------------<br/>0
1
2
3
4
5
6
7
8
9
</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_docs_example_with_harvest.py::test_my_app_bench[A-1-train]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_docs_example_with_harvest.py::test_my_app_bench[A-1-score]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_docs_example_with_harvest.py::test_my_app_bench[A-2-train]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_docs_example_with_harvest.py::test_my_app_bench[A-2-score]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_docs_example_with_harvest.py::test_my_app_bench[B-1-train]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_docs_example_with_harvest.py::test_my_app_bench[B-1-score]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_docs_example_with_harvest.py::test_my_app_bench[B-2-train]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_docs_example_with_harvest.py::test_my_app_bench[B-2-score]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_docs_example_with_harvest.py::test_my_app_bench[C-1-train]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_docs_example_with_harvest.py::test_my_app_bench[C-1-score]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_docs_example_with_harvest.py::test_my_app_bench[C-2-train]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_docs_example_with_harvest.py::test_my_app_bench[C-2-score]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_docs_example_with_harvest.py::test_synthesis</td>
          <td class="col-duration">0.04</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">----------------------------- Captured stdout call -----------------------------<br/>
Keys:
(&#x27;test_my_app_bench[A-1]&#x27;, &#x27;train&#x27;)
(&#x27;test_my_app_bench[A-1]&#x27;, &#x27;score&#x27;)
(&#x27;test_my_app_bench[A-2]&#x27;, &#x27;train&#x27;)
(&#x27;test_my_app_bench[A-2]&#x27;, &#x27;score&#x27;)
(&#x27;test_my_app_bench[B-1]&#x27;, &#x27;train&#x27;)
(&#x27;test_my_app_bench[B-1]&#x27;, &#x27;score&#x27;)
(&#x27;test_my_app_bench[B-2]&#x27;, &#x27;train&#x27;)
(&#x27;test_my_app_bench[B-2]&#x27;, &#x27;score&#x27;)
(&#x27;test_my_app_bench[C-1]&#x27;, &#x27;train&#x27;)
(&#x27;test_my_app_bench[C-1]&#x27;, &#x27;score&#x27;)
(&#x27;test_my_app_bench[C-2]&#x27;, &#x27;train&#x27;)
(&#x27;test_my_app_bench[C-2]&#x27;, &#x27;score&#x27;)

First node:
&#x27;pytest_obj&#x27;: &lt;function test_my_app_bench at 0x7f9fbdb39488&gt;
&#x27;status&#x27;: &#x27;passed&#x27;
&#x27;duration_ms&#x27;: 0.7071495056152344
&#x27;algo_param&#x27;: 1
&#x27;dataset&#x27;: &#x27;my dataset #A&#x27;
&#x27;accuracy&#x27;: 0.9617165218673748
                                     status      duration_ms    algo_param  dataset          accuracy
-----------------------------------  --------  -------------  ------------  -------------  ----------
(&#x27;test_my_app_bench[A-1]&#x27;, &#x27;train&#x27;)  passed         0.70715              1  my dataset #A    0.961717
(&#x27;test_my_app_bench[A-1]&#x27;, &#x27;score&#x27;)  passed         0.688314             1  my dataset #A  nan
(&#x27;test_my_app_bench[A-2]&#x27;, &#x27;train&#x27;)  passed         0.515938             2  my dataset #A    0.473035
(&#x27;test_my_app_bench[A-2]&#x27;, &#x27;score&#x27;)  passed         0.587702             2  my dataset #A  nan
(&#x27;test_my_app_bench[B-1]&#x27;, &#x27;train&#x27;)  passed         0.747919             1  my dataset #B    0.259456
(&#x27;test_my_app_bench[B-1]&#x27;, &#x27;score&#x27;)  passed         0.534534             1  my dataset #B  nan
(&#x27;test_my_app_bench[B-2]&#x27;, &#x27;train&#x27;)  passed         0.644922             2  my dataset #B    0.446133
(&#x27;test_my_app_bench[B-2]&#x27;, &#x27;score&#x27;)  passed         0.69952              2  my dataset #B  nan
(&#x27;test_my_app_bench[C-1]&#x27;, &#x27;train&#x27;)  passed         0.674725             1  my dataset #C    0.698814
(&#x27;test_my_app_bench[C-1]&#x27;, &#x27;score&#x27;)  passed         0.795364             1  my dataset #C  nan
(&#x27;test_my_app_bench[C-2]&#x27;, &#x27;train&#x27;)  passed         0.739098             2  my dataset #C    0.826462
(&#x27;test_my_app_bench[C-2]&#x27;, &#x27;score&#x27;)  passed         0.504971             2  my dataset #C  nan
test_id                   algo_param  dataset        train/status      train/duration_ms    train/accuracy  score/status      score/duration_ms
----------------------  ------------  -------------  --------------  -------------------  ----------------  --------------  -------------------
test_my_app_bench[A-1]             1  my dataset #A  passed                     0.70715           0.961717  passed                     0.688314
test_my_app_bench[A-2]             2  my dataset #A  passed                     0.515938          0.473035  passed                     0.587702
test_my_app_bench[B-1]             1  my dataset #B  passed                     0.747919          0.259456  passed                     0.534534
test_my_app_bench[B-2]             2  my dataset #B  passed                     0.644922          0.446133  passed                     0.69952
test_my_app_bench[C-1]             1  my dataset #C  passed                     0.674725          0.698814  passed                     0.795364
test_my_app_bench[C-2]             2  my dataset #C  passed                     0.739098          0.826462  passed                     0.504971
</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_steps_harvest.py::test_my_app_bench[A-1-train]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_steps_harvest.py::test_my_app_bench[A-1-score]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_steps_harvest.py::test_my_app_bench[A-2-train]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_steps_harvest.py::test_my_app_bench[A-2-score]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_steps_harvest.py::test_my_app_bench[B-1-train]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_steps_harvest.py::test_my_app_bench[B-1-score]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_steps_harvest.py::test_my_app_bench[B-2-train]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_steps_harvest.py::test_my_app_bench[B-2-score]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_steps_harvest.py::test_my_app_bench[C-1-train]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_steps_harvest.py::test_my_app_bench[C-1-score]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_steps_harvest.py::test_my_app_bench[C-2-train]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_steps_harvest.py::test_my_app_bench[C-2-score]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_steps_harvest.py::test_basic</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">pytest_steps/tests/test_steps_harvest.py::test_synthesis</td>
          <td class="col-duration">0.07</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">----------------------------- Captured stdout call -----------------------------<br/>
Keys:
test_my_app_bench[A-1-train]
test_my_app_bench[A-1-score]
test_my_app_bench[A-2-train]
test_my_app_bench[A-2-score]
test_my_app_bench[B-1-train]
test_my_app_bench[B-1-score]
test_my_app_bench[B-2-train]
test_my_app_bench[B-2-score]
test_my_app_bench[C-1-train]
test_my_app_bench[C-1-score]
test_my_app_bench[C-2-train]
test_my_app_bench[C-2-score]
test_basic

First node:
&#x27;pytest_obj&#x27;: &lt;function test_my_app_bench at 0x7f9fbdb2cae8&gt;
&#x27;status&#x27;: &#x27;passed&#x27;
&#x27;duration_ms&#x27;: 0.5440711975097656
&#x27;________step_name_&#x27;: &#x27;train&#x27;
&#x27;algo_param&#x27;: 1
&#x27;dataset&#x27;: &#x27;my dataset #A&#x27;
&#x27;accuracy&#x27;: 0.2276623719048767

Pivoted table:
test_id                   algo_param  dataset        train/status      train/duration_ms    train/accuracy  score/status      score/duration_ms  -/status      -/duration_ms
----------------------  ------------  -------------  --------------  -------------------  ----------------  --------------  -------------------  ----------  ---------------
test_my_app_bench[A-1]             1  my dataset #A  passed                     0.544071          0.227662  passed                     0.710249  nan              nan
test_my_app_bench[A-2]             2  my dataset #A  passed                     0.73266           0.6525    passed                     0.68903   nan              nan
test_my_app_bench[B-1]             1  my dataset #B  passed                     0.477314          0.88012   passed                     1.11055   nan              nan
test_my_app_bench[B-2]             2  my dataset #B  passed                     0.67544           0.162641  passed                     0.70262   nan              nan
test_my_app_bench[C-1]             1  my dataset #C  passed                     0.535965          0.391055  passed                     0.641823  nan              nan
test_my_app_bench[C-2]             2  my dataset #C  passed                     0.733852          0.76703   passed                     0.676155  nan              nan
test_basic                       nan  nan            nan                      nan               nan         nan                      nan         passed             0.482559

Pivoted table (2):
test_id                   algo_param  dataset        train/status      train/duration_ms    train/accuracy  score/status      score/duration_ms  -/status      -/duration_ms
----------------------  ------------  -------------  --------------  -------------------  ----------------  --------------  -------------------  ----------  ---------------
test_my_app_bench[A-1]             1  my dataset #A  passed                     0.544071          0.227662  passed                     0.710249  nan              nan
test_my_app_bench[A-2]             2  my dataset #A  passed                     0.73266           0.6525    passed                     0.68903   nan              nan
test_my_app_bench[B-1]             1  my dataset #B  passed                     0.477314          0.88012   passed                     1.11055   nan              nan
test_my_app_bench[B-2]             2  my dataset #B  passed                     0.67544           0.162641  passed                     0.70262   nan              nan
test_my_app_bench[C-1]             1  my dataset #C  passed                     0.535965          0.391055  passed                     0.641823  nan              nan
test_my_app_bench[C-2]             2  my dataset #C  passed                     0.733852          0.76703   passed                     0.676155  nan              nan
test_basic                       nan  nan            nan                      nan               nan         nan                      nan         passed             0.482559
</div></td></tr></tbody></table></body></html>